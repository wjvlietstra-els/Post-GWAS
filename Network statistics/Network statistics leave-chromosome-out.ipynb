{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the features for the network statistics for leave-SNP-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils import shuffle\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOut = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/vlietstraw/git/Post-GWAS/ENSEMBL_mappings.json\", \"r\") as fp:\n",
    "    ensembl_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph data\n",
    "with open(\"/Users/vlietstraw/git/Post-GWAS/unfiltered_protein_protein_interactions.csv\", 'rb') as input_file:\n",
    "    #next(input_file, '')   # skip a line\n",
    "    G = nx.read_edgelist(input_file, delimiter=',', nodetype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the degrees of the nodes (first metric)\n",
    "degrees = dict(G.degree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of connections between nodes and disease genes (second metrics)\n",
    "def calculate1N(nodeID, diseaseProteins, graph):\n",
    "    if nodeID in diseaseProteins:\n",
    "        diseaseProteins.remove(nodeID)\n",
    "    neighbours = set(dict(graph[nodeID]).keys())\n",
    "    dp_neighbours = neighbours.intersection(diseaseProteins)\n",
    "    return len(dp_neighbours)/len(neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of indirect connectinos between nodes and disease genes (third metric)\n",
    "def calculate2N(nodeID, diseaseProteins, graph):\n",
    "    if nodeID in diseaseProteins:\n",
    "        diseaseProteins.remove(nodeID)\n",
    "    indirect_neighbours_dict = dict(nx.single_source_shortest_path_length(G, source = nodeID, cutoff = 2))\n",
    "    indirect_neighbours = pd.DataFrame({\"nodeID\" : indirect_neighbours_dict.keys(), \"pathLength\" : indirect_neighbours_dict.values()})\n",
    "    indirect_neighbours = indirect_neighbours[indirect_neighbours[\"pathLength\"] == 2]\n",
    "    dp_indirect_neighbours = set(indirect_neighbours[\"nodeID\"]).intersection(diseaseProteins)\n",
    "    if len(indirect_neighbours) > 0:\n",
    "        return len(dp_indirect_neighbours)/len(indirect_neighbours)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average distance to disease genes (fourth metric)\n",
    "def getAverageDPDistance(nodeID, diseaseProteins, graph):\n",
    "    if nodeID in diseaseProteins:\n",
    "        diseaseProteins.remove(nodeID)\n",
    "    shortestPaths = dict(nx.single_source_shortest_path_length(graph, source = nodeID))\n",
    "    dp_shortestPaths = [shortestPaths[x] if x in shortestPaths.keys() else float('inf') for x in diseaseProteins]\n",
    "    output = sum(dp_shortestPaths)/len(dp_shortestPaths)\n",
    "    if output != float('inf'):\n",
    "        return output\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive topology coefficient (fifth metric)\n",
    "def calculateTopologyCoeff(nodeID, diseaseProteins, graph):\n",
    "    coeffs = []\n",
    "    \n",
    "    candidate = set(dict(graph[nodeID]).keys())\n",
    "    for dis in diseaseProteins:\n",
    "        dp = set(dict(graph[dis]).keys())\n",
    "\n",
    "        overlap = dp.intersection(candidate)\n",
    "        if len(overlap) > 0:\n",
    "            coeffs.append(len(overlap) / min(len(dp), len(candidate)))    \n",
    "    if len(coeffs) > 0:\n",
    "        return sum(coeffs) / len(coeffs)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algorithms = [\"LR\", \"SVM\", \"DT\", \"KNN1\", \"KNN3\", \"KNN5\", \"KNN7\", \"KNN9\", \"RF\"]\n",
    "all_bp_distances = [25, 50, 100, 500, 1000, 2000, \"depict\"]\n",
    "refsets = [\"Teslovich\", \"DeRycke\", \"farashi\", \"farashi p-value cutoff\"]\n",
    "\n",
    "all_metrics = pd.DataFrame(list(product(refsets, all_bp_distances, ML_algorithms)), columns = [\"refset\", \"bp distance\", \"algorithm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if writeOut:\n",
    "    all_metrics = all_metrics[all_metrics[\"bp distance\"] == \"depict\"]\n",
    "    all_metrics = all_metrics[((all_metrics[\"algorithm\"] == \"RF\") & (all_metrics[\"refset\"] == \"farashi\")) |\n",
    "                ((all_metrics[\"algorithm\"] == \"LR\") & (all_metrics[\"refset\"] == \"farashi p-value cutoff\")) |\n",
    "                ((all_metrics[\"algorithm\"] == \"RF\") & (all_metrics[\"refset\"] == \"DeRycke\")) |\n",
    "                ((all_metrics[\"algorithm\"] == \"LR\") & (all_metrics[\"refset\"] == \"Teslovich\"))\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting row 55 of 4\n",
      "Predicting candidates for chromosome 1\n",
      "Predicting candidates for chromosome 2\n",
      "Predicting candidates for chromosome 3\n",
      "Predicting candidates for chromosome 4\n",
      "Predicting candidates for chromosome 5\n",
      "Predicting candidates for chromosome 6\n",
      "Predicting candidates for chromosome 7\n",
      "Predicting candidates for chromosome 8\n",
      "Predicting candidates for chromosome 9\n",
      "Predicting candidates for chromosome 10\n",
      "Predicting candidates for chromosome 11\n",
      "Predicting candidates for chromosome 12\n",
      "Predicting candidates for chromosome 15\n",
      "Predicting candidates for chromosome 16\n",
      "Predicting candidates for chromosome 17\n",
      "Predicting candidates for chromosome 19\n",
      "Predicting candidates for chromosome 20\n",
      "Predicting candidates for chromosome 22\n",
      "Predicting row 126 of 4\n",
      "Predicting candidates for chromosome 1\n",
      "Predicting candidates for chromosome 20\n",
      "Predicting candidates for chromosome 17\n",
      "Predicting candidates for chromosome 5\n",
      "Predicting candidates for chromosome 12\n",
      "Predicting candidates for chromosome 6\n",
      "Predicting candidates for chromosome 14\n",
      "Predicting candidates for chromosome 19\n",
      "Predicting candidates for chromosome 9\n",
      "Predicting candidates for chromosome 21\n",
      "Predicting candidates for chromosome 10\n",
      "Predicting candidates for chromosome 2\n",
      "Predicting candidates for chromosome 3\n",
      "Predicting candidates for chromosome 4\n",
      "Predicting candidates for chromosome 16\n",
      "Predicting candidates for chromosome 11\n",
      "Predicting candidates for chromosome 7\n",
      "Predicting candidates for chromosome 22\n",
      "Predicting row 189 of 4\n",
      "Predicting candidates for chromosome 17\n",
      "Predicting candidates for chromosome 12\n",
      "Predicting candidates for chromosome 8\n",
      "Predicting candidates for chromosome 3\n",
      "Predicting candidates for chromosome 16\n",
      "Predicting candidates for chromosome 20\n",
      "Predicting candidates for chromosome 5\n",
      "Predicting candidates for chromosome 21\n",
      "Predicting candidates for chromosome 2\n",
      "Predicting candidates for chromosome 22\n",
      "Predicting candidates for chromosome 1\n",
      "Predicting candidates for chromosome 9\n",
      "Predicting candidates for chromosome 4\n",
      "Predicting candidates for chromosome 7\n",
      "Predicting candidates for chromosome 14\n",
      "Predicting candidates for chromosome 6\n",
      "Predicting candidates for chromosome 19\n",
      "Predicting candidates for chromosome 10\n",
      "Predicting candidates for chromosome 11\n",
      "Predicting row 244 of 4\n",
      "Predicting candidates for chromosome 1\n",
      "Predicting candidates for chromosome 20\n",
      "Predicting candidates for chromosome 14\n",
      "Predicting candidates for chromosome 5\n",
      "Predicting candidates for chromosome 12\n",
      "Predicting candidates for chromosome 6\n",
      "Predicting candidates for chromosome 19\n",
      "Predicting candidates for chromosome 9\n",
      "Predicting candidates for chromosome 8\n",
      "Predicting candidates for chromosome 10\n",
      "Predicting candidates for chromosome 21\n",
      "Predicting candidates for chromosome 3\n",
      "Predicting candidates for chromosome 2\n",
      "Predicting candidates for chromosome 16\n",
      "Predicting candidates for chromosome 11\n",
      "Predicting candidates for chromosome 22\n"
     ]
    }
   ],
   "source": [
    "#Initialize emtpy variables\n",
    "distance_history = 0\n",
    "\n",
    "for am_index, am_values in all_metrics.iterrows():\n",
    "    print(\"Predicting row \" + str(am_index + 1) + \" of \" + str(len(all_metrics)))\n",
    "    \n",
    "    if distance_history != am_values[\"bp distance\"]:\n",
    "        if am_values[\"refset\"] == \"farashi\":\n",
    "            ref = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Input sets/Farashi/Farashi full 2000000 bp distance no pvalue filtering.csv\")\n",
    "\n",
    "        if am_values[\"refset\"] == \"farashi p-value cutoff\":\n",
    "            ref = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Input sets/Farashi/Farashi full 2000000 bp distance no pvalue filtering.csv\")\n",
    "            ref = ref[ref[\"GWAS/eQTL p-value¥\"] <= float(\"5e-8\")]\n",
    "\n",
    "        if am_values[\"refset\"] == \"DeRycke\":\n",
    "            ref = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Input sets/DeRycke/DeRycke reference set.csv\", delimiter = \";\")\n",
    "            ref.columns = [\"SNP ID\", \"chromosome\", \"location\", \"gene_ids\", \"gene name\", \"gene start\", \"gene stop\", \"Diff expression\", \"Class\", \"bp distance absolute\", \"bp distance\", \"Gene rank\"]\n",
    "\n",
    "        if am_values[\"refset\"] == \"Teslovich\":\n",
    "            ref = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Input sets/Teslovich/Teslovich reference set.csv\")\n",
    "            ref.columns = [\"SNP ID\", \"chromosome\", \"location\", \"P\", \"gene_ids\", \"gene name\", \"gene start\", \"gene stop\", \"Class\", \"bp distance absolute\", \"bp distance\", \"Gene rank\"]\n",
    "\n",
    "        ref[\"nodeID\"] = [ensembl_dict[x] if x in ensembl_dict.keys() else None for x in ref[\"gene_ids\"]]\n",
    "\n",
    "        ref = shuffle(ref)\n",
    "        \n",
    "        # Set bp distance cutoff\n",
    "        if am_values[\"bp distance\"] != \"depict\":\n",
    "            max_bp_distance = am_values[\"bp distance\"]\n",
    "            max_bp_distance = max_bp_distance * 1000\n",
    "            ref = ref[ref[\"bp distance absolute\"] <= max_bp_distance]\n",
    "        elif am_values[\"bp distance\"] == \"depict\":\n",
    "            if am_values[\"refset\"] == \"farashi\":\n",
    "                depict = pd.read_csv(\"~/git/DEPICT/outcomes/Farashi complete 2nd round/farashi_no_pvalue_filtering_geneprioritization.txt\", sep = \"\\t\")\n",
    "            if am_values[\"refset\"] == \"farashi p-value cutoff\":\n",
    "                depict = pd.read_csv(\"~/git/DEPICT/outcomes/Farashi complete 2nd round/farashi_default_pvalue_filtering_geneprioritization.txt\", sep = \"\\t\")\n",
    "            if am_values[\"refset\"] == \"DeRycke\":\n",
    "                depict = pd.read_csv(\"~/git/DEPICT/outcomes/DeRycke/DeRycke_output_geneprioritization.txt\", sep = \"\\t\")\n",
    "            if am_values[\"refset\"] == \"Teslovich\":\n",
    "                depict = pd.read_csv(\"~/git/DEPICT/outcomes/Teslovich for paper Wytze/Teslovich_output_geneprioritization.txt\", sep = \"\\t\")\n",
    "            depict[\"nodeID\"] = [ensembl_dict[x] if x in ensembl_dict.keys() else None for x in depict[\"Ensembl gene ID\"]]\n",
    "\n",
    "\n",
    "            depict[\"Locus\"] = depict[\"Locus\"].astype(str).apply(lambda x: x.split(\";\"))\n",
    "            depict = depict.explode(\"Locus\")\n",
    "\n",
    "            snp_replacement_dict = {\"rs113645266\" : \"rs6557271\",\n",
    "                            \"rs150282463\" : \"rs13137700\",\n",
    "                            \"rs67276543\" : \"rs34884832\"}\n",
    "            depict[\"Locus\"] = depict[\"Locus\"].replace(snp_replacement_dict)\n",
    "\n",
    "            depict = depict[[\"Locus\", \"nodeID\"]]\n",
    "            depict.columns = [\"SNP ID\", \"nodeID\"]\n",
    "\n",
    "            ref = ref.merge(depict, on = [\"SNP ID\", \"nodeID\"], how = \"inner\")\n",
    "\n",
    "        # Drop all unmappable candidates\n",
    "        ref.dropna(subset = [\"nodeID\"], inplace = True)\n",
    "        ref[\"nodeID\"] = ref[\"nodeID\"].astype(int)\n",
    "\n",
    "        # Drop all SNPs which no longer have a positive case\n",
    "        pos_counts = ref.groupby(\"SNP ID\")[\"Class\"].sum()\n",
    "        ref = ref[~ref[\"SNP ID\"].isin(pos_counts[pos_counts == 0].index)]\n",
    "        \n",
    "        f = ref.groupby(\"nodeID\")[\"Class\"].sum()\n",
    "        f[f > 1] = 1\n",
    "        f = pd.DataFrame(f)\n",
    "        \n",
    "        f[\"degree\"] = [degrees[x] for x in list(f.index)]\n",
    "        f[\"1N index\"] = [calculate1N(x, set(f.index).intersection(set(ref[\"nodeID\"][(ref[\"Class\"] == 1) & (~ref[\"chromosome\"].isin(ref[\"chromosome\"][ref[\"nodeID\"] == x]))])), G) for x in list(f.index)]\n",
    "        f[\"2N index\"] = [calculate2N(x, set(f.index).intersection(set(ref[\"nodeID\"][(ref[\"Class\"] == 1) & (~ref[\"chromosome\"].isin(ref[\"chromosome\"][ref[\"nodeID\"] == x]))])), G) for x in list(f.index)]\n",
    "        f[\"Average DP Distance\"] = [getAverageDPDistance(x, set(f.index).intersection(set(ref[\"nodeID\"][(ref[\"Class\"] == 1) & (~ref[\"chromosome\"].isin(ref[\"chromosome\"][ref[\"nodeID\"] == x]))])), G) for x in list(f.index)]\n",
    "        f[\"Topology coefficient\"] = [calculateTopologyCoeff(x, set(f.index).intersection(set(ref[\"nodeID\"][(ref[\"Class\"] == 1) & (~ref[\"chromosome\"].isin(ref[\"chromosome\"][ref[\"nodeID\"] == x]))])), G) for x in list(f.index)]\n",
    "    \n",
    "    if !writeOut:\n",
    "        distance_history = am_values[\"bp distance\"]\n",
    "\n",
    "    outcomes2 = pd.DataFrame()\n",
    "    train_auc_score2 = []\n",
    "    train_auc_rank2 = []\n",
    "\n",
    "    # In[12]:\n",
    "\n",
    "    classifier = am_values[\"algorithm\"]\n",
    "    \n",
    "    # Perform leave-SNP-out cross validation\n",
    "    chromosomes = list(set(ref[\"chromosome\"]))\n",
    "\n",
    "    for chrom in chromosomes:\n",
    "        print(\"Predicting candidates for chromosome \" + str(chrom))\n",
    "\n",
    "        f_test = f[f.index.isin(ref[\"nodeID\"][ref[\"chromosome\"] == chrom])].copy()\n",
    "        f_train = f[f.index.isin(ref[\"nodeID\"][ref[\"chromosome\"] != chrom])].copy()\n",
    "\n",
    "        train_class = f[\"Class\"][f.index.isin(f_train.index)]\n",
    "        test_class = f[\"Class\"][f.index.isin(f_test.index)]\n",
    "\n",
    "        f_test.drop(columns = [\"Class\"], inplace = True)\n",
    "        f_train.drop(columns = [\"Class\"], inplace = True)\n",
    "\n",
    "        if classifier == \"SVM\":\n",
    "            clf = SVR(gamma=\"auto\")\n",
    "        if classifier == \"DT\":\n",
    "            clf = DecisionTreeRegressor()\n",
    "        if classifier == \"KNN1\":\n",
    "            clf = KNeighborsRegressor(n_neighbors = 1)\n",
    "        if classifier == \"KNN3\":\n",
    "            clf = KNeighborsRegressor(n_neighbors = 3)\n",
    "        if classifier == \"KNN5\" and len(f_train) >= 5:\n",
    "            clf = KNeighborsRegressor(n_neighbors = 5)\n",
    "        if classifier == \"KNN5\" and len(f_train) < 5:\n",
    "            continue\n",
    "        if classifier == \"KNN7\" and len(f_train) >= 7:\n",
    "            clf = KNeighborsRegressor(n_neighbors = 7)\n",
    "        if classifier == \"KNN7\" and len(f_train) < 7:\n",
    "            continue\n",
    "        if classifier == \"KNN9\" and len(f_train) >= 9:\n",
    "            clf = KNeighborsRegressor(n_neighbors = 9)\n",
    "        if classifier == \"KNN9\" and len(f_train) < 9:\n",
    "            continue\n",
    "        if classifier == \"LR\":\n",
    "            from warnings import filterwarnings\n",
    "            filterwarnings('ignore')\n",
    "            clf = LogisticRegression()\n",
    "        if classifier == \"RF\":\n",
    "            clf = RandomForestRegressor(n_estimators = 1000, n_jobs = -1, max_features = \"sqrt\", max_depth = 5)\n",
    "\n",
    "        clf.fit(np.array(f_train), np.array(train_class))\n",
    "\n",
    "        if classifier == \"LR\":\n",
    "            outcomes2 = pd.concat([outcomes2, pd.DataFrame({\"predicted\" : clf.predict_proba(f_test)[:,1],\n",
    "                                                \"Class\" : test_class,\n",
    "                                                \"chromosome\" : chrom,\n",
    "                                                \"nodeID\" : f_test.index})])\n",
    "        else:\n",
    "            outcomes2 = pd.concat([outcomes2, pd.DataFrame({\"predicted\" : clf.predict(f_test),\n",
    "                                                            \"Class\" : test_class,\n",
    "                                                            \"chromosome\" : chrom,\n",
    "                                                            \"nodeID\" : f_test.index})])\n",
    "    if len(outcomes2) > 0:\n",
    "        outcomes2.index.name = None\n",
    "        outcomes2 = outcomes2.sort_values([\"chromosome\", \"predicted\"], ascending = False)\n",
    "        outcomes2[\"For-chromosome rank\"] = outcomes2.groupby(\"chromosome\").cumcount() + 1\n",
    "\n",
    "        # In[29]:\n",
    "\n",
    "\n",
    "        chromosomes = list(set(outcomes2[\"chromosome\"]))\n",
    "        aucs = []\n",
    "        for chrom in chromosomes:\n",
    "          fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcomes2[\"Class\"][outcomes2[\"chromosome\"] == chrom], -outcomes2[\"For-chromosome rank\"][outcomes2[\"chromosome\"] == chrom], pos_label = 1)\n",
    "          aucs.append(sklearn.metrics.auc(fpr, tpr))\n",
    "        all_metrics.at[am_index, \"ROC-AUC per chromosome\"] = sum(aucs)/len(aucs)\n",
    "\n",
    "\n",
    "        # In[30]:\n",
    "\n",
    "\n",
    "        ref = ref.merge(outcomes2[[\"nodeID\", \"predicted\"]], on = \"nodeID\", how = \"left\")\n",
    "\n",
    "        all_metrics.at[am_index, \"Recall snps\"] = len(set(ref[\"SNP ID\"]))\n",
    "        all_metrics.at[am_index, \"Recall entries\"] = sum(ref[\"Class\"])\n",
    "        all_metrics.at[am_index, \"Recall genes\"] = len(set(ref[\"nodeID\"][ref[\"Class\"] == 1]))\n",
    "\n",
    "        # In[31]:\n",
    "\n",
    "\n",
    "        ref = ref.sort_values([\"SNP ID\", \"predicted\"], ascending = False)\n",
    "        \n",
    "        SNP_temp = 0\n",
    "        counter = 0\n",
    "        prediction_temp = 9999\n",
    "        for indx, row in ref.iterrows():\n",
    "            if SNP_temp != row[\"SNP ID\"]:\n",
    "                SNP_temp = row[\"SNP ID\"]\n",
    "                counter = 1\n",
    "                prediction_temp = row[\"predicted\"]\n",
    "            elif SNP_temp == row[\"SNP ID\"] and prediction_temp != row[\"predicted\"]:\n",
    "                counter += 1\n",
    "                prediction_temp = row[\"predicted\"]\n",
    "            ref.at[indx, \"For-SNP rank\"] = counter\n",
    "\n",
    "        if writeOut:\n",
    "            ref_out = ref[[\"SNP ID\", \"nodeID\", \"predicted\", \"Class\", \"For-SNP rank\"]]\n",
    "            ref_out[\"For-SNP rank\"] = ref_out[\"For-SNP rank\"].astype(int)\n",
    "            ref_out.to_csv(\"/Users/vlietstraw/git/Post-GWAS/Network statistics/\" + am_values[\"refset\"] + \" \"+ am_values[\"algorithm\"] + \" \" + am_values[\"bp distance\"] + \" \" + datetime.today().strftime(\"%d-%m-%Y\") + \".csv\", sep = \";\", index = False)\n",
    "\n",
    "        # In[32]:\n",
    "\n",
    "\n",
    "        fpr, tpr, thresholds = sklearn.metrics.roc_curve(ref[\"Class\"], -ref[\"For-SNP rank\"], pos_label = 1)\n",
    "        all_metrics.at[am_index, \"ROC-AUC overall (lco)\"] = sklearn.metrics.auc(fpr, tpr) * 100\n",
    "\n",
    "\n",
    "        # In[33]:\n",
    "\n",
    "\n",
    "        # Calculate the ROC-AUC for every SNP and average the result\n",
    "        SNPS2 = list(set(ref[\"SNP ID\"]))\n",
    "        aucs = []\n",
    "        for snp in SNPS2:\n",
    "          if len(set(ref[\"Class\"][ref[\"SNP ID\"] == snp])) == 1:\n",
    "              aucs.append(list(set(ref[\"Class\"][ref[\"SNP ID\"] == snp]))[0])\n",
    "          else:\n",
    "              fpr, tpr, thresholds = sklearn.metrics.roc_curve(ref[\"Class\"][ref[\"SNP ID\"] == snp], -ref[\"For-SNP rank\"][ref[\"SNP ID\"] == snp], pos_label = 1)\n",
    "              aucs.append(sklearn.metrics.auc(fpr, tpr))\n",
    "        all_metrics.at[am_index, \"ROC-AUC - mean per snpl (lco)\"] = sum(aucs)/len(aucs)\n",
    "\n",
    "\n",
    "        # In[34]:\n",
    "\n",
    "\n",
    "        # Calculate hits @1\n",
    "        all_metrics.at[am_index, \"Hits@1(lco)\"] = sum(ref[\"Class\"][(ref[\"Class\"] == 1) & (ref[\"For-SNP rank\"] == 1)])\n",
    "\n",
    "\n",
    "        # In[35]:\n",
    "\n",
    "\n",
    "        # Calculate hits @3\n",
    "        all_metrics.at[am_index, \"Hits@3(lco)\"] = sum(ref[\"Class\"][(ref[\"Class\"] == 1) & (ref[\"For-SNP rank\"] <= 3)])\n",
    "\n",
    "\n",
    "        # In[36]:\n",
    "\n",
    "\n",
    "        # Calculate hits @5\n",
    "        all_metrics.at[am_index, \"Hits@5(lco)\"] = sum(ref[\"Class\"][(ref[\"Class\"] == 1) & (ref[\"For-SNP rank\"] <= 5)])\n",
    "\n",
    "\n",
    "        # In[37]:\n",
    "\n",
    "\n",
    "        # Calculate hits @10\n",
    "        all_metrics.at[am_index, \"Hits@10(lco)\"] = sum(ref[\"Class\"][(ref[\"Class\"] == 1) & (ref[\"For-SNP rank\"] <= 10)])\n",
    "\n",
    "\n",
    "        # In[38]:\n",
    "\n",
    "\n",
    "        all_metrics.at[am_index, \"Mean rank (lco)\"] = ref[\"For-SNP rank\"][(ref[\"Class\"] == 1)].mean()\n",
    "\n",
    "\n",
    "        # In[39]:\n",
    "\n",
    "\n",
    "        all_metrics.at[am_index, \"Median rank (lco)\"] = ref[\"For-SNP rank\"][ref[\"Class\"] == 1].quantile(q = [0,0.25,0.5,0.75,1])[.50]\n",
    "        ref.drop(columns = [\"predicted\", \"For-SNP rank\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.to_csv(\"/Users/vlietstraw/git//Post-GWAS/Network statistics/Leave-chromosome-out all metrics \" + datetime.today().strftime(\"%d-%m-%Y\") + \".csv\", sep = \";\", decimal = \",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
