{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as prep\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(object):\n",
    "    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus,\n",
    "                 optimizer = tf.train.AdamOptimizer(), scale = 0.0):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.transfer = transfer_function\n",
    "        self.scale = tf.placeholder(tf.float32)\n",
    "        self.training_scale = scale\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights\n",
    "        self.x = tf.placeholder(tf.float32,[None, self.n_input])\n",
    "        self.hidden = self.transfer(tf.add(tf.matmul(self.x + scale * tf.random_normal((n_input,)),\n",
    "                                                     self.weights['w1']), self.weights['b1']))\n",
    "        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']),self.weights['b2'])\n",
    "        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.Variable(xavier_init(self.n_input, self.n_hidden))\n",
    "        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden],dtype= tf.float32))\n",
    "        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype= tf.float32))\n",
    "        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype= tf.float32))\n",
    "        return all_weights\n",
    "    def partial_fit(self,X ):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict= {self.x: X,\n",
    "                                                                           self.scale: self.training_scale})\n",
    "        return cost\n",
    "    def before_loss(self, X):\n",
    "        cost = self.sess.run((self.cost), feed_dict={self.x: X,\n",
    "                                                                          self.scale: self.training_scale})\n",
    "        return cost\n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.hidden, feed_dict= {self.x : X, self.scale: self.training_scale})\n",
    "    def generate(self, hidden = None):\n",
    "        if hidden is None:\n",
    "            #print(self.weights[\"b1\"].shape)\n",
    "            hidden = np.random.normal( size = self.weights[\"b1\"])\n",
    "            #hidden = np.random.normal(size=self.weights[\"b1\"].shape)\n",
    "\n",
    "\n",
    "        return self.sess.run(self.reconstruction, feed_dict= {self.hidden: hidden})\n",
    "    ###这块的reconstruction是初始化定义的w* x + b\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        ##这块的重建是指整体运行一边复原过程\n",
    "        return self.sess.run(self.reconstruction, feed_dict={self.x : X, self.scale: self.training_scale})\n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'])\n",
    "    def getBias(self):\n",
    "        return self.sess.run(self.weights['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=open(\"autorcode_weighted_emb.txt\",\"w\")\n",
    "file2=open(\"gene.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(X_train):\n",
    "    preprocessor = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    return X_train\n",
    "\n",
    "def get_random_block_from_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index: (start_index + batch_size)]\n",
    "\n",
    "def xavier_init(fan_in, fan_out, constant = 1):\n",
    "    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), minval = low, maxval = high, dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneSet=set()\n",
    "data=[]\n",
    "for lines in open(r\"/Users/vlietstraw/git/Post-GWAS/Struc2vec/PathwayStudio_PPI_complete_directed_weighted-copy_for_autoencoder.emb\",\"r\"):\n",
    "    line=lines.strip().split()\n",
    "    geneSet.add(line[0])\n",
    "    file2.write(line[0])\n",
    "    file2.write(\"\\n\")\n",
    "    list1=[]\n",
    "    for l in line[1:]:\n",
    "        list1.append(float(l))\n",
    "    data.append(list1)\n",
    "#print (geneSet)\n",
    "#print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/envs/SNP-gene/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "training_epochs =1000\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "input_n_size = [128, 256]\n",
    "hidden_size = [350, 100]\n",
    "sdne = []\n",
    "\n",
    "for i in range(1):\n",
    "    if i== 0:\n",
    "        ae = Autoencoder(n_input = input_n_size[0], n_hidden = hidden_size[0], transfer_function = tf.nn.elu,\n",
    "                             optimizer = tf.train.AdamOptimizer(learning_rate= 0.0001),\n",
    "                             scale = 0)\n",
    "        \n",
    "        sdne.append(ae)\n",
    "    else:\n",
    "        ae = Autoencoder(n_input = input_n_size[1], n_hidden = hidden_size[1], transfer_function = tf.nn.sigmoid,\n",
    "                             optimizer = tf.train.AdagradOptimizer(learning_rate= 0.01),\n",
    "                             scale = 0)\n",
    "        \n",
    "        sdne.append(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 每个样本上的误差: 62.275099905\n",
      "Epoch:    2 每个样本上的误差: 51.200883477\n",
      "Epoch:    3 每个样本上的误差: 44.515954608\n",
      "Epoch:    4 每个样本上的误差: 33.658476831\n",
      "Epoch:    5 每个样本上的误差: 25.374288782\n",
      "Epoch:    6 每个样本上的误差: 21.502958872\n",
      "Epoch:    7 每个样本上的误差: 17.373965014\n",
      "Epoch:    8 每个样本上的误差: 13.105975904\n",
      "Epoch:    9 每个样本上的误差: 11.419138231\n",
      "Epoch:   10 每个样本上的误差: 8.375121046\n",
      "Epoch:   11 每个样本上的误差: 7.202194368\n",
      "Epoch:   12 每个样本上的误差: 5.963159524\n",
      "Epoch:   13 每个样本上的误差: 4.794178044\n",
      "Epoch:   14 每个样本上的误差: 4.114817019\n",
      "Epoch:   15 每个样本上的误差: 3.272358602\n",
      "Epoch:   16 每个样本上的误差: 2.751270615\n",
      "Epoch:   17 每个样本上的误差: 2.256647479\n",
      "Epoch:   18 每个样本上的误差: 1.876559970\n",
      "Epoch:   19 每个样本上的误差: 1.465129484\n",
      "Epoch:   20 每个样本上的误差: 1.331942450\n",
      "Epoch:   21 每个样本上的误差: 1.189357246\n",
      "Epoch:   22 每个样本上的误差: 0.966633334\n",
      "Epoch:   23 每个样本上的误差: 0.881974942\n",
      "Epoch:   24 每个样本上的误差: 0.778096614\n",
      "Epoch:   25 每个样本上的误差: 0.728024434\n",
      "Epoch:   26 每个样本上的误差: 0.659806368\n",
      "Epoch:   27 每个样本上的误差: 0.631000789\n",
      "Epoch:   28 每个样本上的误差: 0.585021159\n",
      "Epoch:   29 每个样本上的误差: 0.586820364\n",
      "Epoch:   30 每个样本上的误差: 0.551953940\n",
      "Epoch:   31 每个样本上的误差: 0.548457008\n",
      "Epoch:   32 每个样本上的误差: 0.528370849\n",
      "Epoch:   33 每个样本上的误差: 0.514135396\n",
      "Epoch:   34 每个样本上的误差: 0.496210973\n",
      "Epoch:   35 每个样本上的误差: 0.487191542\n",
      "Epoch:   36 每个样本上的误差: 0.461913602\n",
      "Epoch:   37 每个样本上的误差: 0.460513425\n",
      "Epoch:   38 每个样本上的误差: 0.448575646\n",
      "Epoch:   39 每个样本上的误差: 0.436946006\n",
      "Epoch:   40 每个样本上的误差: 0.429521800\n",
      "Epoch:   41 每个样本上的误差: 0.414975563\n",
      "Epoch:   42 每个样本上的误差: 0.417312518\n",
      "Epoch:   43 每个样本上的误差: 0.411516167\n",
      "Epoch:   44 每个样本上的误差: 0.405044705\n",
      "Epoch:   45 每个样本上的误差: 0.389746406\n",
      "Epoch:   46 每个样本上的误差: 0.375934205\n",
      "Epoch:   47 每个样本上的误差: 0.377165489\n",
      "Epoch:   48 每个样本上的误差: 0.360218582\n",
      "Epoch:   49 每个样本上的误差: 0.368577841\n",
      "Epoch:   50 每个样本上的误差: 0.350983433\n",
      "Epoch:   51 每个样本上的误差: 0.348181381\n",
      "Epoch:   52 每个样本上的误差: 0.340351702\n",
      "Epoch:   53 每个样本上的误差: 0.341186747\n",
      "Epoch:   54 每个样本上的误差: 0.330399443\n",
      "Epoch:   55 每个样本上的误差: 0.312652314\n",
      "Epoch:   56 每个样本上的误差: 0.316430037\n",
      "Epoch:   57 每个样本上的误差: 0.316580749\n",
      "Epoch:   58 每个样本上的误差: 0.305331020\n",
      "Epoch:   59 每个样本上的误差: 0.299791273\n",
      "Epoch:   60 每个样本上的误差: 0.293538033\n",
      "Epoch:   61 每个样本上的误差: 0.281620226\n",
      "Epoch:   62 每个样本上的误差: 0.285595832\n",
      "Epoch:   63 每个样本上的误差: 0.279968445\n",
      "Epoch:   64 每个样本上的误差: 0.272728703\n",
      "Epoch:   65 每个样本上的误差: 0.269089379\n",
      "Epoch:   66 每个样本上的误差: 0.263391320\n",
      "Epoch:   67 每个样本上的误差: 0.257609574\n",
      "Epoch:   68 每个样本上的误差: 0.255975283\n",
      "Epoch:   69 每个样本上的误差: 0.252883781\n",
      "Epoch:   70 每个样本上的误差: 0.249884488\n",
      "Epoch:   71 每个样本上的误差: 0.241881649\n",
      "Epoch:   72 每个样本上的误差: 0.240859574\n",
      "Epoch:   73 每个样本上的误差: 0.233259567\n",
      "Epoch:   74 每个样本上的误差: 0.227320694\n",
      "Epoch:   75 每个样本上的误差: 0.230817431\n",
      "Epoch:   76 每个样本上的误差: 0.228918666\n",
      "Epoch:   77 每个样本上的误差: 0.220367411\n",
      "Epoch:   78 每个样本上的误差: 0.219809525\n",
      "Epoch:   79 每个样本上的误差: 0.216770897\n",
      "Epoch:   80 每个样本上的误差: 0.205478868\n",
      "Epoch:   81 每个样本上的误差: 0.208829415\n",
      "Epoch:   82 每个样本上的误差: 0.203811293\n",
      "Epoch:   83 每个样本上的误差: 0.203420949\n",
      "Epoch:   84 每个样本上的误差: 0.199368859\n",
      "Epoch:   85 每个样本上的误差: 0.199759270\n",
      "Epoch:   86 每个样本上的误差: 0.193265736\n",
      "Epoch:   87 每个样本上的误差: 0.194701758\n",
      "Epoch:   88 每个样本上的误差: 0.189295442\n",
      "Epoch:   89 每个样本上的误差: 0.187700076\n",
      "Epoch:   90 每个样本上的误差: 0.187328384\n",
      "Epoch:   91 每个样本上的误差: 0.180264600\n",
      "Epoch:   92 每个样本上的误差: 0.177560218\n",
      "Epoch:   93 每个样本上的误差: 0.173416742\n",
      "Epoch:   94 每个样本上的误差: 0.173520725\n",
      "Epoch:   95 每个样本上的误差: 0.169402320\n",
      "Epoch:   96 每个样本上的误差: 0.168320424\n",
      "Epoch:   97 每个样本上的误差: 0.164835058\n",
      "Epoch:   98 每个样本上的误差: 0.164358742\n",
      "Epoch:   99 每个样本上的误差: 0.161905522\n",
      "Epoch:  100 每个样本上的误差: 0.155408557\n",
      "Epoch:  101 每个样本上的误差: 0.152947246\n",
      "Epoch:  102 每个样本上的误差: 0.152136381\n",
      "Epoch:  103 每个样本上的误差: 0.152898281\n",
      "Epoch:  104 每个样本上的误差: 0.146057484\n",
      "Epoch:  105 每个样本上的误差: 0.147396390\n",
      "Epoch:  106 每个样本上的误差: 0.145331767\n",
      "Epoch:  107 每个样本上的误差: 0.141198392\n",
      "Epoch:  108 每个样本上的误差: 0.141609925\n",
      "Epoch:  109 每个样本上的误差: 0.139898843\n",
      "Epoch:  110 每个样本上的误差: 0.137688121\n",
      "Epoch:  111 每个样本上的误差: 0.134033261\n",
      "Epoch:  112 每个样本上的误差: 0.130854671\n",
      "Epoch:  113 每个样本上的误差: 0.130541106\n",
      "Epoch:  114 每个样本上的误差: 0.128552546\n",
      "Epoch:  115 每个样本上的误差: 0.127894788\n",
      "Epoch:  116 每个样本上的误差: 0.126086108\n",
      "Epoch:  117 每个样本上的误差: 0.123963403\n",
      "Epoch:  118 每个样本上的误差: 0.122883906\n",
      "Epoch:  119 每个样本上的误差: 0.121296852\n",
      "Epoch:  120 每个样本上的误差: 0.120219132\n",
      "Epoch:  121 每个样本上的误差: 0.117266177\n",
      "Epoch:  122 每个样本上的误差: 0.116465384\n",
      "Epoch:  123 每个样本上的误差: 0.113852100\n",
      "Epoch:  124 每个样本上的误差: 0.113101277\n",
      "Epoch:  125 每个样本上的误差: 0.112267728\n",
      "Epoch:  126 每个样本上的误差: 0.108601800\n",
      "Epoch:  127 每个样本上的误差: 0.109705848\n",
      "Epoch:  128 每个样本上的误差: 0.107220214\n",
      "Epoch:  129 每个样本上的误差: 0.106000470\n",
      "Epoch:  130 每个样本上的误差: 0.103486360\n",
      "Epoch:  131 每个样本上的误差: 0.100486844\n",
      "Epoch:  132 每个样本上的误差: 0.100722580\n",
      "Epoch:  133 每个样本上的误差: 0.099598650\n",
      "Epoch:  134 每个样本上的误差: 0.099845906\n",
      "Epoch:  135 每个样本上的误差: 0.096737045\n",
      "Epoch:  136 每个样本上的误差: 0.094923695\n",
      "Epoch:  137 每个样本上的误差: 0.093903301\n",
      "Epoch:  138 每个样本上的误差: 0.091504565\n",
      "Epoch:  139 每个样本上的误差: 0.088697084\n",
      "Epoch:  140 每个样本上的误差: 0.089410958\n",
      "Epoch:  141 每个样本上的误差: 0.090181384\n",
      "Epoch:  142 每个样本上的误差: 0.089934244\n",
      "Epoch:  143 每个样本上的误差: 0.084768155\n",
      "Epoch:  144 每个样本上的误差: 0.084183459\n",
      "Epoch:  145 每个样本上的误差: 0.083685767\n",
      "Epoch:  146 每个样本上的误差: 0.082200677\n",
      "Epoch:  147 每个样本上的误差: 0.082536659\n",
      "Epoch:  148 每个样本上的误差: 0.081855653\n",
      "Epoch:  149 每个样本上的误差: 0.079814203\n",
      "Epoch:  150 每个样本上的误差: 0.078228654\n",
      "Epoch:  151 每个样本上的误差: 0.077307990\n",
      "Epoch:  152 每个样本上的误差: 0.076975830\n",
      "Epoch:  153 每个样本上的误差: 0.073418637\n",
      "Epoch:  154 每个样本上的误差: 0.075031973\n",
      "Epoch:  155 每个样本上的误差: 0.073697112\n",
      "Epoch:  156 每个样本上的误差: 0.071664834\n",
      "Epoch:  157 每个样本上的误差: 0.069438387\n",
      "Epoch:  158 每个样本上的误差: 0.068667241\n",
      "Epoch:  159 每个样本上的误差: 0.069860401\n",
      "Epoch:  160 每个样本上的误差: 0.067847938\n",
      "Epoch:  161 每个样本上的误差: 0.065271574\n",
      "Epoch:  162 每个样本上的误差: 0.067686419\n",
      "Epoch:  163 每个样本上的误差: 0.065870930\n",
      "Epoch:  164 每个样本上的误差: 0.062907464\n",
      "Epoch:  165 每个样本上的误差: 0.063182037\n",
      "Epoch:  166 每个样本上的误差: 0.062683250\n",
      "Epoch:  167 每个样本上的误差: 0.060005268\n",
      "Epoch:  168 每个样本上的误差: 0.060645086\n",
      "Epoch:  169 每个样本上的误差: 0.060221623\n",
      "Epoch:  170 每个样本上的误差: 0.059751875\n",
      "Epoch:  171 每个样本上的误差: 0.058549091\n",
      "Epoch:  172 每个样本上的误差: 0.057976738\n",
      "Epoch:  173 每个样本上的误差: 0.057407028\n",
      "Epoch:  174 每个样本上的误差: 0.055523859\n",
      "Epoch:  175 每个样本上的误差: 0.056077199\n",
      "Epoch:  176 每个样本上的误差: 0.054278880\n",
      "Epoch:  177 每个样本上的误差: 0.054210051\n",
      "Epoch:  178 每个样本上的误差: 0.052200579\n",
      "Epoch:  179 每个样本上的误差: 0.052413265\n",
      "Epoch:  180 每个样本上的误差: 0.052461749\n",
      "Epoch:  181 每个样本上的误差: 0.050697338\n",
      "Epoch:  182 每个样本上的误差: 0.050277638\n",
      "Epoch:  183 每个样本上的误差: 0.050560310\n",
      "Epoch:  184 每个样本上的误差: 0.048370472\n",
      "Epoch:  185 每个样本上的误差: 0.046711152\n",
      "Epoch:  186 每个样本上的误差: 0.046702357\n",
      "Epoch:  187 每个样本上的误差: 0.046242518\n",
      "Epoch:  188 每个样本上的误差: 0.045706331\n",
      "Epoch:  189 每个样本上的误差: 0.045420930\n",
      "Epoch:  190 每个样本上的误差: 0.043862560\n",
      "Epoch:  191 每个样本上的误差: 0.044265110\n",
      "Epoch:  192 每个样本上的误差: 0.044038757\n",
      "Epoch:  193 每个样本上的误差: 0.042617064\n",
      "Epoch:  194 每个样本上的误差: 0.041820235\n",
      "Epoch:  195 每个样本上的误差: 0.041088669\n",
      "Epoch:  196 每个样本上的误差: 0.041088765\n",
      "Epoch:  197 每个样本上的误差: 0.040331631\n",
      "Epoch:  198 每个样本上的误差: 0.040034637\n",
      "Epoch:  199 每个样本上的误差: 0.039589223\n",
      "Epoch:  200 每个样本上的误差: 0.038672613\n",
      "Epoch:  201 每个样本上的误差: 0.038224450\n",
      "Epoch:  202 每个样本上的误差: 0.037535083\n",
      "Epoch:  203 每个样本上的误差: 0.037005727\n",
      "Epoch:  204 每个样本上的误差: 0.035972901\n",
      "Epoch:  205 每个样本上的误差: 0.036414525\n",
      "Epoch:  206 每个样本上的误差: 0.035529184\n",
      "Epoch:  207 每个样本上的误差: 0.034795298\n",
      "Epoch:  208 每个样本上的误差: 0.034963264\n",
      "Epoch:  209 每个样本上的误差: 0.033673249\n",
      "Epoch:  210 每个样本上的误差: 0.033590432\n",
      "Epoch:  211 每个样本上的误差: 0.032875626\n",
      "Epoch:  212 每个样本上的误差: 0.031994986\n",
      "Epoch:  213 每个样本上的误差: 0.032302982\n",
      "Epoch:  214 每个样本上的误差: 0.031673821\n",
      "Epoch:  215 每个样本上的误差: 0.031549029\n",
      "Epoch:  216 每个样本上的误差: 0.031129841\n",
      "Epoch:  217 每个样本上的误差: 0.029865775\n",
      "Epoch:  218 每个样本上的误差: 0.029723212\n",
      "Epoch:  219 每个样本上的误差: 0.028816913\n",
      "Epoch:  220 每个样本上的误差: 0.028789025\n",
      "Epoch:  221 每个样本上的误差: 0.028805030\n",
      "Epoch:  222 每个样本上的误差: 0.028073954\n",
      "Epoch:  223 每个样本上的误差: 0.026724301\n",
      "Epoch:  224 每个样本上的误差: 0.026734519\n",
      "Epoch:  225 每个样本上的误差: 0.026674740\n",
      "Epoch:  226 每个样本上的误差: 0.026442123\n",
      "Epoch:  227 每个样本上的误差: 0.025800025\n",
      "Epoch:  228 每个样本上的误差: 0.025399692\n",
      "Epoch:  229 每个样本上的误差: 0.024504197\n",
      "Epoch:  230 每个样本上的误差: 0.025060093\n",
      "Epoch:  231 每个样本上的误差: 0.024435701\n",
      "Epoch:  232 每个样本上的误差: 0.023613501\n",
      "Epoch:  233 每个样本上的误差: 0.023689991\n",
      "Epoch:  234 每个样本上的误差: 0.023611936\n",
      "Epoch:  235 每个样本上的误差: 0.022990599\n",
      "Epoch:  236 每个样本上的误差: 0.022464021\n",
      "Epoch:  237 每个样本上的误差: 0.022123417\n",
      "Epoch:  238 每个样本上的误差: 0.022483396\n",
      "Epoch:  239 每个样本上的误差: 0.021313329\n",
      "Epoch:  240 每个样本上的误差: 0.020733486\n",
      "Epoch:  241 每个样本上的误差: 0.020787079\n",
      "Epoch:  242 每个样本上的误差: 0.020736743\n",
      "Epoch:  243 每个样本上的误差: 0.020876078\n",
      "Epoch:  244 每个样本上的误差: 0.020239521\n",
      "Epoch:  245 每个样本上的误差: 0.019729422\n",
      "Epoch:  246 每个样本上的误差: 0.019306996\n",
      "Epoch:  247 每个样本上的误差: 0.019378116\n",
      "Epoch:  248 每个样本上的误差: 0.019435363\n",
      "Epoch:  249 每个样本上的误差: 0.019008381\n",
      "Epoch:  250 每个样本上的误差: 0.018626586\n",
      "Epoch:  251 每个样本上的误差: 0.018446073\n",
      "Epoch:  252 每个样本上的误差: 0.018204016\n",
      "Epoch:  253 每个样本上的误差: 0.017868516\n",
      "Epoch:  254 每个样本上的误差: 0.017614568\n",
      "Epoch:  255 每个样本上的误差: 0.017348976\n",
      "Epoch:  256 每个样本上的误差: 0.017022595\n",
      "Epoch:  257 每个样本上的误差: 0.016335616\n",
      "Epoch:  258 每个样本上的误差: 0.016439248\n",
      "Epoch:  259 每个样本上的误差: 0.016118303\n",
      "Epoch:  260 每个样本上的误差: 0.016191308\n",
      "Epoch:  261 每个样本上的误差: 0.015397027\n",
      "Epoch:  262 每个样本上的误差: 0.015519822\n",
      "Epoch:  263 每个样本上的误差: 0.015621312\n",
      "Epoch:  264 每个样本上的误差: 0.014932183\n",
      "Epoch:  265 每个样本上的误差: 0.014754937\n",
      "Epoch:  266 每个样本上的误差: 0.014227180\n",
      "Epoch:  267 每个样本上的误差: 0.014462900\n",
      "Epoch:  268 每个样本上的误差: 0.014313031\n",
      "Epoch:  269 每个样本上的误差: 0.014080106\n",
      "Epoch:  270 每个样本上的误差: 0.013770806\n",
      "Epoch:  271 每个样本上的误差: 0.013655710\n",
      "Epoch:  272 每个样本上的误差: 0.013215387\n",
      "Epoch:  273 每个样本上的误差: 0.012836068\n",
      "Epoch:  274 每个样本上的误差: 0.012817140\n",
      "Epoch:  275 每个样本上的误差: 0.013143142\n",
      "Epoch:  276 每个样本上的误差: 0.012761366\n",
      "Epoch:  277 每个样本上的误差: 0.012465106\n",
      "Epoch:  278 每个样本上的误差: 0.012565119\n",
      "Epoch:  279 每个样本上的误差: 0.011984483\n",
      "Epoch:  280 每个样本上的误差: 0.012300560\n",
      "Epoch:  281 每个样本上的误差: 0.011908081\n",
      "Epoch:  282 每个样本上的误差: 0.011477523\n",
      "Epoch:  283 每个样本上的误差: 0.011308681\n",
      "Epoch:  284 每个样本上的误差: 0.011455490\n",
      "Epoch:  285 每个样本上的误差: 0.011227197\n",
      "Epoch:  286 每个样本上的误差: 0.010812962\n",
      "Epoch:  287 每个样本上的误差: 0.010871083\n",
      "Epoch:  288 每个样本上的误差: 0.010574151\n",
      "Epoch:  289 每个样本上的误差: 0.010634238\n",
      "Epoch:  290 每个样本上的误差: 0.010123784\n",
      "Epoch:  291 每个样本上的误差: 0.010146913\n",
      "Epoch:  292 每个样本上的误差: 0.010098507\n",
      "Epoch:  293 每个样本上的误差: 0.009864682\n",
      "Epoch:  294 每个样本上的误差: 0.009811656\n",
      "Epoch:  295 每个样本上的误差: 0.009583177\n",
      "Epoch:  296 每个样本上的误差: 0.009471949\n",
      "Epoch:  297 每个样本上的误差: 0.008963309\n",
      "Epoch:  298 每个样本上的误差: 0.009005546\n",
      "Epoch:  299 每个样本上的误差: 0.008779928\n",
      "Epoch:  300 每个样本上的误差: 0.008932591\n",
      "14422\n"
     ]
    }
   ],
   "source": [
    "W = []\n",
    "b = []\n",
    "Hidden_feature = []\n",
    "\n",
    "for j in range(1):\n",
    "    if j == 0:\n",
    "        X_train = standard_scale(data)\n",
    "    else:\n",
    "        X_train_pre = X_train\n",
    "        X_train = sdne[j-1].transform(X_train_pre)\n",
    "        Hidden_feature.append(X_train)\n",
    "    epoch=0\n",
    "    for epoch in range(300):\n",
    "        total_cost = 0.\n",
    "        total_batch = int(X_train.shape[0] / batch_size)\n",
    "\n",
    "        for k in range(total_batch):\n",
    "\n",
    "            batch_xs = get_random_block_from_data(X_train, batch_size)\n",
    "\n",
    "            cost = sdne[j].partial_fit(batch_xs)\n",
    "            total_cost=total_cost+cost\n",
    "        loss=total_cost/13460\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", \"%4d\" % (epoch + 1), \"每个样本上的误差:\", \"{:.9f}\".format(loss))\n",
    "            \n",
    "    if j == 0:\n",
    "        feat0 = sdne[0].transform(standard_scale(data))\n",
    "        print (len(feat0))\n",
    "        for feat in feat0:\n",
    "            for f in feat:\n",
    "                file1.write(str(f))\n",
    "                file1.write(\"\\t\")\n",
    "            file1.write(\"\\n\")\n",
    "file1.close()\n",
    "\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
