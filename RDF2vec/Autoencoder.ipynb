{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as prep\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(object):\n",
    "    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus,\n",
    "                 optimizer = tf.train.AdamOptimizer(), scale = 0.0):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.transfer = transfer_function\n",
    "        self.scale = tf.placeholder(tf.float32)\n",
    "        self.training_scale = scale\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights\n",
    "        self.x = tf.placeholder(tf.float32,[None, self.n_input])\n",
    "        self.hidden = self.transfer(tf.add(tf.matmul(self.x + scale * tf.random_normal((n_input,)),\n",
    "                                                     self.weights['w1']), self.weights['b1']))\n",
    "        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']),self.weights['b2'])\n",
    "        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.Variable(xavier_init(self.n_input, self.n_hidden))\n",
    "        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden],dtype= tf.float32))\n",
    "        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype= tf.float32))\n",
    "        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype= tf.float32))\n",
    "        return all_weights\n",
    "    def partial_fit(self,X ):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict= {self.x: X,\n",
    "                                                                           self.scale: self.training_scale})\n",
    "        return cost\n",
    "    def before_loss(self, X):\n",
    "        cost = self.sess.run((self.cost), feed_dict={self.x: X,\n",
    "                                                                          self.scale: self.training_scale})\n",
    "        return cost\n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.hidden, feed_dict= {self.x : X, self.scale: self.training_scale})\n",
    "    def generate(self, hidden = None):\n",
    "        if hidden is None:\n",
    "            #print(self.weights[\"b1\"].shape)\n",
    "            hidden = np.random.normal( size = self.weights[\"b1\"])\n",
    "            #hidden = np.random.normal(size=self.weights[\"b1\"].shape)\n",
    "\n",
    "\n",
    "        return self.sess.run(self.reconstruction, feed_dict= {self.hidden: hidden})\n",
    "    ###这块的reconstruction是初始化定义的w* x + b\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        ##这块的重建是指整体运行一边复原过程\n",
    "        return self.sess.run(self.reconstruction, feed_dict={self.x : X, self.scale: self.training_scale})\n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'])\n",
    "    def getBias(self):\n",
    "        return self.sess.run(self.weights['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=open(\"autorcode_teslovich_emb.txt\",\"w\")\n",
    "file2=open(\"gene.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(X_train):\n",
    "    preprocessor = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    return X_train\n",
    "\n",
    "def get_random_block_from_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index: (start_index + batch_size)]\n",
    "\n",
    "def xavier_init(fan_in, fan_out, constant = 1):\n",
    "    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), minval = low, maxval = high, dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneSet=set()\n",
    "data=[]\n",
    "for lines in open(r\"/Users/vlietstraw/git/Post-GWAS/RDF2vec/Teslovich complete protein-protein embeddings-copy_for_autoencoder.csv\",\"r\"):\n",
    "    line=lines.strip().split(\",\")\n",
    "    geneSet.add(line[0])\n",
    "    file2.write(line[0])\n",
    "    file2.write(\"\\n\")\n",
    "    list1=[]\n",
    "    for l in line[1:]:\n",
    "        list1.append(float(l))\n",
    "    data.append(list1)\n",
    "#print (geneSet)\n",
    "#print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/envs/SNP-gene/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "training_epochs =1000\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "input_n_size = [500, 256]\n",
    "hidden_size = [350, 100]\n",
    "sdne = []\n",
    "\n",
    "for i in range(1):\n",
    "    if i== 0:\n",
    "        ae = Autoencoder(n_input = input_n_size[0], n_hidden = hidden_size[0], transfer_function = tf.nn.elu,\n",
    "                             optimizer = tf.train.AdamOptimizer(learning_rate= 0.0001),\n",
    "                             scale = 0)\n",
    "        \n",
    "        sdne.append(ae)\n",
    "    else:\n",
    "        ae = Autoencoder(n_input = input_n_size[1], n_hidden = hidden_size[1], transfer_function = tf.nn.sigmoid,\n",
    "                             optimizer = tf.train.AdagradOptimizer(learning_rate= 0.01),\n",
    "                             scale = 0)\n",
    "        \n",
    "        sdne.append(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 每个样本上的误差: 47.504869173\n",
      "Epoch:    2 每个样本上的误差: 45.880476296\n",
      "Epoch:    3 每个样本上的误差: 43.588263257\n",
      "Epoch:    4 每个样本上的误差: 41.639104290\n",
      "Epoch:    5 每个样本上的误差: 40.399507801\n",
      "Epoch:    6 每个样本上的误差: 39.396671852\n",
      "Epoch:    7 每个样本上的误差: 36.583674139\n",
      "Epoch:    8 每个样本上的误差: 35.937546724\n",
      "Epoch:    9 每个样本上的误差: 34.305099310\n",
      "Epoch:   10 每个样本上的误差: 33.456623212\n",
      "Epoch:   11 每个样本上的误差: 32.402004202\n",
      "Epoch:   12 每个样本上的误差: 31.467950176\n",
      "Epoch:   13 每个样本上的误差: 30.676814404\n",
      "Epoch:   14 每个样本上的误差: 30.453396638\n",
      "Epoch:   15 每个样本上的误差: 29.882407655\n",
      "Epoch:   16 每个样本上的误差: 28.097108330\n",
      "Epoch:   17 每个样本上的误差: 27.653887967\n",
      "Epoch:   18 每个样本上的误差: 27.044964246\n",
      "Epoch:   19 每个样本上的误差: 27.002685910\n",
      "Epoch:   20 每个样本上的误差: 26.374213236\n",
      "Epoch:   21 每个样本上的误差: 25.129403963\n",
      "Epoch:   22 每个样本上的误差: 24.443949666\n",
      "Epoch:   23 每个样本上的误差: 24.430407951\n",
      "Epoch:   24 每个样本上的误差: 23.711628059\n",
      "Epoch:   25 每个样本上的误差: 23.566188011\n",
      "Epoch:   26 每个样本上的误差: 22.743358504\n",
      "Epoch:   27 每个样本上的误差: 22.935392047\n",
      "Epoch:   28 每个样本上的误差: 22.231930692\n",
      "Epoch:   29 每个样本上的误差: 21.347736058\n",
      "Epoch:   30 每个样本上的误差: 21.121977300\n",
      "Epoch:   31 每个样本上的误差: 20.941629713\n",
      "Epoch:   32 每个样本上的误差: 20.228507354\n",
      "Epoch:   33 每个样本上的误差: 20.182540572\n",
      "Epoch:   34 每个样本上的误差: 19.460110977\n",
      "Epoch:   35 每个样本上的误差: 19.287542226\n",
      "Epoch:   36 每个样本上的误差: 19.122174644\n",
      "Epoch:   37 每个样本上的误差: 18.686699886\n",
      "Epoch:   38 每个样本上的误差: 18.709659408\n",
      "Epoch:   39 每个样本上的误差: 18.574328740\n",
      "Epoch:   40 每个样本上的误差: 17.864705174\n",
      "Epoch:   41 每个样本上的误差: 18.225238844\n",
      "Epoch:   42 每个样本上的误差: 17.732827011\n",
      "Epoch:   43 每个样本上的误差: 17.497591243\n",
      "Epoch:   44 每个样本上的误差: 17.309242518\n",
      "Epoch:   45 每个样本上的误差: 16.619865719\n",
      "Epoch:   46 每个样本上的误差: 16.789733470\n",
      "Epoch:   47 每个样本上的误差: 16.128149233\n",
      "Epoch:   48 每个样本上的误差: 16.128539713\n",
      "Epoch:   49 每个样本上的误差: 15.973645146\n",
      "Epoch:   50 每个样本上的误差: 15.740115969\n",
      "Epoch:   51 每个样本上的误差: 15.593444697\n",
      "Epoch:   52 每个样本上的误差: 15.436737178\n",
      "Epoch:   53 每个样本上的误差: 15.091756681\n",
      "Epoch:   54 每个样本上的误差: 15.130066517\n",
      "Epoch:   55 每个样本上的误差: 14.657813516\n",
      "Epoch:   56 每个样本上的误差: 14.812563266\n",
      "Epoch:   57 每个样本上的误差: 14.729484207\n",
      "Epoch:   58 每个样本上的误差: 14.020075977\n",
      "Epoch:   59 每个样本上的误差: 14.305886945\n",
      "Epoch:   60 每个样本上的误差: 14.343504191\n",
      "Epoch:   61 每个样本上的误差: 13.899847204\n",
      "Epoch:   62 每个样本上的误差: 13.854201105\n",
      "Epoch:   63 每个样本上的误差: 13.498514841\n",
      "Epoch:   64 每个样本上的误差: 13.529490591\n",
      "Epoch:   65 每个样本上的误差: 13.309011220\n",
      "Epoch:   66 每个样本上的误差: 12.997114715\n",
      "Epoch:   67 每个样本上的误差: 13.100065225\n",
      "Epoch:   68 每个样本上的误差: 12.600616990\n",
      "Epoch:   69 每个样本上的误差: 12.900673727\n",
      "Epoch:   70 每个样本上的误差: 12.670241833\n",
      "Epoch:   71 每个样本上的误差: 12.616769160\n",
      "Epoch:   72 每个样本上的误差: 12.341344362\n",
      "Epoch:   73 每个样本上的误差: 11.998622437\n",
      "Epoch:   74 每个样本上的误差: 12.139711196\n",
      "Epoch:   75 每个样本上的误差: 12.401640712\n",
      "Epoch:   76 每个样本上的误差: 12.109070640\n",
      "Epoch:   77 每个样本上的误差: 11.839854198\n",
      "Epoch:   78 每个样本上的误差: 11.493850776\n",
      "Epoch:   79 每个样本上的误差: 11.373199962\n",
      "Epoch:   80 每个样本上的误差: 11.198777410\n",
      "Epoch:   81 每个样本上的误差: 11.743029259\n",
      "Epoch:   82 每个样本上的误差: 11.328864532\n",
      "Epoch:   83 每个样本上的误差: 11.435629223\n",
      "Epoch:   84 每个样本上的误差: 11.180626480\n",
      "Epoch:   85 每个样本上的误差: 10.924330989\n",
      "Epoch:   86 每个样本上的误差: 10.769686151\n",
      "Epoch:   87 每个样本上的误差: 10.740118653\n",
      "Epoch:   88 每个样本上的误差: 10.647777268\n",
      "Epoch:   89 每个样本上的误差: 10.461942866\n",
      "Epoch:   90 每个样本上的误差: 11.016264119\n",
      "Epoch:   91 每个样本上的误差: 10.801723640\n",
      "Epoch:   92 每个样本上的误差: 10.527893991\n",
      "Epoch:   93 每个样本上的误差: 10.366864422\n",
      "Epoch:   94 每个样本上的误差: 10.646689772\n",
      "Epoch:   95 每个样本上的误差: 10.623747374\n",
      "Epoch:   96 每个样本上的误差: 9.992766908\n",
      "Epoch:   97 每个样本上的误差: 9.965117565\n",
      "Epoch:   98 每个样本上的误差: 9.991991462\n",
      "Epoch:   99 每个样本上的误差: 10.012774976\n",
      "Epoch:  100 每个样本上的误差: 9.774452225\n",
      "Epoch:  101 每个样本上的误差: 9.867269557\n",
      "Epoch:  102 每个样本上的误差: 9.779760053\n",
      "Epoch:  103 每个样本上的误差: 9.835485785\n",
      "Epoch:  104 每个样本上的误差: 9.483844711\n",
      "Epoch:  105 每个样本上的误差: 9.313523359\n",
      "Epoch:  106 每个样本上的误差: 9.502379736\n",
      "Epoch:  107 每个样本上的误差: 9.556729720\n",
      "Epoch:  108 每个样本上的误差: 9.246534872\n",
      "Epoch:  109 每个样本上的误差: 9.261067733\n",
      "Epoch:  110 每个样本上的误差: 8.986121349\n",
      "Epoch:  111 每个样本上的误差: 9.220973457\n",
      "Epoch:  112 每个样本上的误差: 8.920498381\n",
      "Epoch:  113 每个样本上的误差: 8.921538282\n",
      "Epoch:  114 每个样本上的误差: 9.251706155\n",
      "Epoch:  115 每个样本上的误差: 8.759587290\n",
      "Epoch:  116 每个样本上的误差: 8.674093669\n",
      "Epoch:  117 每个样本上的误差: 8.826228104\n",
      "Epoch:  118 每个样本上的误差: 8.658440373\n",
      "Epoch:  119 每个样本上的误差: 8.700998111\n",
      "Epoch:  120 每个样本上的误差: 8.556040467\n",
      "Epoch:  121 每个样本上的误差: 8.442965413\n",
      "Epoch:  122 每个样本上的误差: 8.558933153\n",
      "Epoch:  123 每个样本上的误差: 8.352435892\n",
      "Epoch:  124 每个样本上的误差: 8.320241326\n",
      "Epoch:  125 每个样本上的误差: 8.321923756\n",
      "Epoch:  126 每个样本上的误差: 8.151242034\n",
      "Epoch:  127 每个样本上的误差: 8.550868096\n",
      "Epoch:  128 每个样本上的误差: 8.367239811\n",
      "Epoch:  129 每个样本上的误差: 8.011217699\n",
      "Epoch:  130 每个样本上的误差: 7.940873058\n",
      "Epoch:  131 每个样本上的误差: 8.156084870\n",
      "Epoch:  132 每个样本上的误差: 8.025834359\n",
      "Epoch:  133 每个样本上的误差: 7.844981441\n",
      "Epoch:  134 每个样本上的误差: 8.095707261\n",
      "Epoch:  135 每个样本上的误差: 7.769697759\n",
      "Epoch:  136 每个样本上的误差: 7.855311963\n",
      "Epoch:  137 每个样本上的误差: 7.928455696\n",
      "Epoch:  138 每个样本上的误差: 7.700158601\n",
      "Epoch:  139 每个样本上的误差: 7.611145654\n",
      "Epoch:  140 每个样本上的误差: 7.530598330\n",
      "Epoch:  141 每个样本上的误差: 7.612850648\n",
      "Epoch:  142 每个样本上的误差: 7.663341034\n",
      "Epoch:  143 每个样本上的误差: 7.408668987\n",
      "Epoch:  144 每个样本上的误差: 7.501340125\n",
      "Epoch:  145 每个样本上的误差: 7.380110193\n",
      "Epoch:  146 每个样本上的误差: 7.220155205\n",
      "Epoch:  147 每个样本上的误差: 7.243632900\n",
      "Epoch:  148 每个样本上的误差: 7.466157466\n",
      "Epoch:  149 每个样本上的误差: 7.400541753\n",
      "Epoch:  150 每个样本上的误差: 7.168120241\n",
      "Epoch:  151 每个样本上的误差: 7.056329518\n",
      "Epoch:  152 每个样本上的误差: 7.219124446\n",
      "Epoch:  153 每个样本上的误差: 7.299500255\n",
      "Epoch:  154 每个样本上的误差: 7.185961297\n",
      "Epoch:  155 每个样本上的误差: 6.696655165\n",
      "Epoch:  156 每个样本上的误差: 6.820478719\n",
      "Epoch:  157 每个样本上的误差: 6.954915752\n",
      "Epoch:  158 每个样本上的误差: 6.936600706\n",
      "Epoch:  159 每个样本上的误差: 6.923552134\n",
      "Epoch:  160 每个样本上的误差: 7.049011756\n",
      "Epoch:  161 每个样本上的误差: 6.839612088\n",
      "Epoch:  162 每个样本上的误差: 6.564843242\n",
      "Epoch:  163 每个样本上的误差: 6.636875537\n",
      "Epoch:  164 每个样本上的误差: 6.513654245\n",
      "Epoch:  165 每个样本上的误差: 6.762806826\n",
      "Epoch:  166 每个样本上的误差: 6.532438199\n",
      "Epoch:  167 每个样本上的误差: 6.622794101\n",
      "Epoch:  168 每个样本上的误差: 6.510253471\n",
      "Epoch:  169 每个样本上的误差: 6.611569291\n",
      "Epoch:  170 每个样本上的误差: 6.384631692\n",
      "Epoch:  171 每个样本上的误差: 6.717680280\n",
      "Epoch:  172 每个样本上的误差: 6.380862966\n",
      "Epoch:  173 每个样本上的误差: 6.329916622\n",
      "Epoch:  174 每个样本上的误差: 6.580523165\n",
      "Epoch:  175 每个样本上的误差: 6.464987477\n",
      "Epoch:  176 每个样本上的误差: 6.537267758\n",
      "Epoch:  177 每个样本上的误差: 6.426135526\n",
      "Epoch:  178 每个样本上的误差: 6.223091386\n",
      "Epoch:  179 每个样本上的误差: 6.394728957\n",
      "Epoch:  180 每个样本上的误差: 6.153744602\n",
      "Epoch:  181 每个样本上的误差: 6.242608452\n",
      "Epoch:  182 每个样本上的误差: 6.234422776\n",
      "Epoch:  183 每个样本上的误差: 6.123976387\n",
      "Epoch:  184 每个样本上的误差: 6.163153629\n",
      "Epoch:  185 每个样本上的误差: 6.074021696\n",
      "Epoch:  186 每个样本上的误差: 6.019438128\n",
      "Epoch:  187 每个样本上的误差: 5.993164498\n",
      "Epoch:  188 每个样本上的误差: 6.143973100\n",
      "Epoch:  189 每个样本上的误差: 6.084252567\n",
      "Epoch:  190 每个样本上的误差: 5.955239120\n",
      "Epoch:  191 每个样本上的误差: 5.959942364\n",
      "Epoch:  192 每个样本上的误差: 5.912836972\n",
      "Epoch:  193 每个样本上的误差: 5.930608306\n",
      "Epoch:  194 每个样本上的误差: 5.673137095\n",
      "Epoch:  195 每个样本上的误差: 5.742960044\n",
      "Epoch:  196 每个样本上的误差: 6.189004857\n",
      "Epoch:  197 每个样本上的误差: 5.756160687\n",
      "Epoch:  198 每个样本上的误差: 5.660342675\n",
      "Epoch:  199 每个样本上的误差: 5.633367494\n",
      "Epoch:  200 每个样本上的误差: 5.870801035\n",
      "Epoch:  201 每个样本上的误差: 5.616167877\n",
      "Epoch:  202 每个样本上的误差: 5.794430474\n",
      "Epoch:  203 每个样本上的误差: 5.753183840\n",
      "Epoch:  204 每个样本上的误差: 5.729762447\n",
      "Epoch:  205 每个样本上的误差: 5.584889473\n",
      "Epoch:  206 每个样本上的误差: 5.419904571\n",
      "Epoch:  207 每个样本上的误差: 5.520734395\n",
      "Epoch:  208 每个样本上的误差: 5.585871948\n",
      "Epoch:  209 每个样本上的误差: 5.452239455\n",
      "Epoch:  210 每个样本上的误差: 5.550528185\n",
      "Epoch:  211 每个样本上的误差: 5.695426372\n",
      "Epoch:  212 每个样本上的误差: 5.289729914\n",
      "Epoch:  213 每个样本上的误差: 5.455287730\n",
      "Epoch:  214 每个样本上的误差: 5.303069751\n",
      "Epoch:  215 每个样本上的误差: 5.251473187\n",
      "Epoch:  216 每个样本上的误差: 5.309714983\n",
      "Epoch:  217 每个样本上的误差: 5.131020334\n",
      "Epoch:  218 每个样本上的误差: 5.801859677\n",
      "Epoch:  219 每个样本上的误差: 5.469284534\n",
      "Epoch:  220 每个样本上的误差: 5.711500184\n",
      "Epoch:  221 每个样本上的误差: 5.293741620\n",
      "Epoch:  222 每个样本上的误差: 5.167772785\n",
      "Epoch:  223 每个样本上的误差: 5.129781964\n",
      "Epoch:  224 每个样本上的误差: 5.536921934\n",
      "Epoch:  225 每个样本上的误差: 5.370319356\n",
      "Epoch:  226 每个样本上的误差: 5.077545991\n",
      "Epoch:  227 每个样本上的误差: 5.188906003\n",
      "Epoch:  228 每个样本上的误差: 5.083524535\n",
      "Epoch:  229 每个样本上的误差: 5.153078095\n",
      "Epoch:  230 每个样本上的误差: 4.980144946\n",
      "Epoch:  231 每个样本上的误差: 5.037374229\n",
      "Epoch:  232 每个样本上的误差: 5.312711927\n",
      "Epoch:  233 每个样本上的误差: 5.196458220\n",
      "Epoch:  234 每个样本上的误差: 5.252970571\n",
      "Epoch:  235 每个样本上的误差: 4.882610186\n",
      "Epoch:  236 每个样本上的误差: 4.912044622\n",
      "Epoch:  237 每个样本上的误差: 4.974515818\n",
      "Epoch:  238 每个样本上的误差: 5.105755116\n",
      "Epoch:  239 每个样本上的误差: 5.106640262\n",
      "Epoch:  240 每个样本上的误差: 4.942690328\n",
      "Epoch:  241 每个样本上的误差: 5.254254613\n",
      "Epoch:  242 每个样本上的误差: 4.990708654\n",
      "Epoch:  243 每个样本上的误差: 4.776828697\n",
      "Epoch:  244 每个样本上的误差: 4.880942992\n",
      "Epoch:  245 每个样本上的误差: 4.898168800\n",
      "Epoch:  246 每个样本上的误差: 4.806593611\n",
      "Epoch:  247 每个样本上的误差: 4.897458144\n",
      "Epoch:  248 每个样本上的误差: 4.866164939\n",
      "Epoch:  249 每个样本上的误差: 4.814966582\n",
      "Epoch:  250 每个样本上的误差: 4.749938729\n",
      "Epoch:  251 每个样本上的误差: 5.034784017\n",
      "Epoch:  252 每个样本上的误差: 4.832181870\n",
      "Epoch:  253 每个样本上的误差: 4.875038634\n",
      "Epoch:  254 每个样本上的误差: 4.871438739\n",
      "Epoch:  255 每个样本上的误差: 4.591750768\n",
      "Epoch:  256 每个样本上的误差: 4.733032626\n",
      "Epoch:  257 每个样本上的误差: 4.766959321\n",
      "Epoch:  258 每个样本上的误差: 4.716513374\n",
      "Epoch:  259 每个样本上的误差: 4.544044674\n",
      "Epoch:  260 每个样本上的误差: 4.571871409\n",
      "Epoch:  261 每个样本上的误差: 4.571998558\n",
      "Epoch:  262 每个样本上的误差: 4.653897181\n",
      "Epoch:  263 每个样本上的误差: 4.530520444\n",
      "Epoch:  264 每个样本上的误差: 4.442400334\n",
      "Epoch:  265 每个样本上的误差: 4.756954598\n",
      "Epoch:  266 每个样本上的误差: 4.625702095\n",
      "Epoch:  267 每个样本上的误差: 4.399689764\n",
      "Epoch:  268 每个样本上的误差: 4.523190421\n",
      "Epoch:  269 每个样本上的误差: 4.518026393\n",
      "Epoch:  270 每个样本上的误差: 4.651269277\n",
      "Epoch:  271 每个样本上的误差: 4.438528003\n",
      "Epoch:  272 每个样本上的误差: 4.425160523\n",
      "Epoch:  273 每个样本上的误差: 4.771609746\n",
      "Epoch:  274 每个样本上的误差: 4.596985208\n",
      "Epoch:  275 每个样本上的误差: 4.656403268\n",
      "Epoch:  276 每个样本上的误差: 4.401624170\n",
      "Epoch:  277 每个样本上的误差: 4.589726251\n",
      "Epoch:  278 每个样本上的误差: 4.437118372\n",
      "Epoch:  279 每个样本上的误差: 4.554598768\n",
      "Epoch:  280 每个样本上的误差: 4.443581895\n",
      "Epoch:  281 每个样本上的误差: 4.477254619\n",
      "Epoch:  282 每个样本上的误差: 4.498095812\n",
      "Epoch:  283 每个样本上的误差: 4.420492540\n",
      "Epoch:  284 每个样本上的误差: 4.390203939\n",
      "Epoch:  285 每个样本上的误差: 4.375956828\n",
      "Epoch:  286 每个样本上的误差: 4.470629919\n",
      "Epoch:  287 每个样本上的误差: 4.275019045\n",
      "Epoch:  288 每个样本上的误差: 4.380630507\n",
      "Epoch:  289 每个样本上的误差: 4.347638221\n",
      "Epoch:  290 每个样本上的误差: 4.178525021\n",
      "Epoch:  291 每个样本上的误差: 4.249987956\n",
      "Epoch:  292 每个样本上的误差: 4.298089355\n",
      "Epoch:  293 每个样本上的误差: 4.523489738\n",
      "Epoch:  294 每个样本上的误差: 4.345234723\n",
      "Epoch:  295 每个样本上的误差: 4.222021230\n",
      "Epoch:  296 每个样本上的误差: 4.206678788\n",
      "Epoch:  297 每个样本上的误差: 4.092796691\n",
      "Epoch:  298 每个样本上的误差: 4.216267130\n",
      "Epoch:  299 每个样本上的误差: 4.003300614\n",
      "Epoch:  300 每个样本上的误差: 4.057474440\n",
      "2695\n"
     ]
    }
   ],
   "source": [
    "W = []\n",
    "b = []\n",
    "Hidden_feature = []\n",
    "\n",
    "for j in range(1):\n",
    "    if j == 0:\n",
    "        X_train = standard_scale(data)\n",
    "    else:\n",
    "        X_train_pre = X_train\n",
    "        X_train = sdne[j-1].transform(X_train_pre)\n",
    "        Hidden_feature.append(X_train)\n",
    "    epoch=0\n",
    "    for epoch in range(300):\n",
    "        total_cost = 0.\n",
    "        total_batch = int(X_train.shape[0] / batch_size)\n",
    "\n",
    "        for k in range(total_batch):\n",
    "\n",
    "            batch_xs = get_random_block_from_data(X_train, batch_size)\n",
    "\n",
    "            cost = sdne[j].partial_fit(batch_xs)\n",
    "            total_cost=total_cost+cost\n",
    "        loss=total_cost/13460\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", \"%4d\" % (epoch + 1), \"每个样本上的误差:\", \"{:.9f}\".format(loss))\n",
    "            \n",
    "    if j == 0:\n",
    "        feat0 = sdne[0].transform(standard_scale(data))\n",
    "        print (len(feat0))\n",
    "        for feat in feat0:\n",
    "            for f in feat:\n",
    "                file1.write(str(f))\n",
    "                file1.write(\"\\t\")\n",
    "            file1.write(\"\\n\")\n",
    "file1.close()\n",
    "\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
