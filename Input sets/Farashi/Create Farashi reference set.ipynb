{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat referense sets for the Farashi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = 2000000\n",
    "FC_cutoff = 1.5\n",
    "FDR_cutoff = 0.0001\n",
    "distance_filter = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data of Farashi et al. that is used as a reference set\n",
    "farashi = pd.read_excel(\"41568_2018_87_MOESM1_ESM-3.xls\", header = 1)\n",
    "\n",
    "# Remove the empty rows at the bottom\n",
    "farashi = farashi[farashi[\"SNP ID\"].notnull() & farashi[\"Target/assigned/e-Gene\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate entries for cells with delimited genes\n",
    "farashi[\"Target/assigned/e-Gene\"] = farashi[\"Target/assigned/e-Gene\"].str.replace(\", \", \";\")\n",
    "farashi = farashi.assign(gene=farashi[\"Target/assigned/e-Gene\"].str.split(';')).explode('gene')\n",
    "\n",
    "# One gene has as postfix \"FoxA1 binding\", which we manually remove\n",
    "farashi.drop(farashi[farashi[\"gene\"] == \"FoxA1 binding\"].index, inplace = True)\n",
    "\n",
    "# Strip whitespaces\n",
    "farashi[\"gene\"] = farashi[\"gene\"].str.strip()\n",
    "\n",
    "# Some gene names are outdated/erroneous. These are manually mapped to correct genes as decribed above\n",
    "gene_replacement_dictionary = { \"MSMB1\" : \"MSMB\",\n",
    "                                \"MSMB2\" : \"MSMB\",\n",
    "                                \"NCOA4-1\" : \"NCOA4P1\",\n",
    "                                \"NCOA4-3\" : \"NCOA4P3\", \n",
    "                                \"ANKRD5\" : \"ANKEF1\", \n",
    "                                \"C6orf228\" : \"SMIM13\",\n",
    "                                \"HoxB13\" : \"HOXB13\",\n",
    "                                \"LASS2\" : \"CERS2\",\n",
    "                                \"C10orf32\" : \"BORCS7\",\n",
    "                                \"LOC100505761\" : \"RPARP-AS1\",\n",
    "                                \"LOC100505495\" : \"PCAT19\",\n",
    "                                \"WDR52\" : \"CFAP44\",\n",
    "                                \"HCG4P6\" : \"HCG4B\",\n",
    "                                \"LOC285830\" : \"HLA-F-AS1\",\n",
    "                                \"RAB7L1\" : \"RAB29\",\n",
    "                                \"LOC284578\" : \"MFSD4A-AS1\",\n",
    "                                \"AGAP7\" : \"AGAP7P\",\n",
    "                                \"C2orf43\" : \"LDAH\",\n",
    "                                \"FAM96B\" : \"CIAO2B\",\n",
    "                                \"TMEM180\" : \"MFSD13A\",\n",
    "                                \"WBSCR27\" : \"METTL27\",\n",
    "                                \"KLK3 (PSA)\" : \"KLK3\",\n",
    "                                \"PCAT1 (lncRNA)\" : \"PCAT1\",\n",
    "                                \"SUV420H1\" : \"KMT5B\",\n",
    "                                \"c-MYC\" : \"MYC\",\n",
    "                                \"AL391261.1\" : \"NCOA4P1\"}\n",
    "\n",
    "farashi[\"gene\"] = farashi[\"gene\"].replace(gene_replacement_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace fault-inducing postfixes for snp data\n",
    "farashi[\"SNP ID\"] = farashi[\"SNP ID\"].str.strip()\n",
    "farashi[\"SNP ID\"].replace(\"(_A)|(_C)\", \"\", regex = True, inplace = True)\n",
    "\n",
    "# Remove entries without valid rs identifiers\n",
    "farashi.drop(farashi[farashi[\"SNP ID\"].str.startswith(\"chr\")].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionary\n",
    "snp_replacement_dictionary = {\"rs565245309\" : \"rs10700825\",\n",
    "                              \"rs397764955\" : \"rs11371876\",\n",
    "                              \"rs567544918\" : \"rs143009074\",\n",
    "                              \"rs68007409\" : \"rs58061354\",\n",
    "                              \"rs576874987\" : \"rs2735090\",\n",
    "                              \"rs56969947\" : \"rs5794883\",\n",
    "                              \"rs71390080\" : \"rs35883900\",\n",
    "                              \"rs397885676\" : \"rs35853071\",\n",
    "                              \"rs563936332\" : \"rs11425106\",\n",
    "                              \"rs570238728\" :  \"rs2735091\",\n",
    "                              \"rs386572937\" : \"rs2735095\",\n",
    "                              \"rs368454874\" : \"rs5875242\",\n",
    "                              \"rs576956856\" : \"rs557303655\",\n",
    "                              \"rs527768094\" : \"rs3115587\",\n",
    "                              \"rs34421549\" : \"rs11281315\",\n",
    "                              \"rs543833159\" : \"rs9261476\",\n",
    "                              \"rs573341295\" : \"rs3083610\",\n",
    "                              \"rs397841490\" : \"rs3839562\",\n",
    "                              \"rs72562630\" : \"rs10643878\",\n",
    "                              \"rs67276543\" : \"rs34884832\",\n",
    "                              \"rs113645266\" : \"rs6557271\",\n",
    "                              \"rs540840764\" : \"rs9278594\",\n",
    "                              \"rs145076668\" : \"rs34837204\",\n",
    "                              \"rs79588872\" : \"rs35538902\",\n",
    "                              \"rs397847839\" : \"rs35826034\",\n",
    "                              \"rs551993434\" : \"rs11371951\",\n",
    "                              \"rs113130272\" : \"rs11153141\",\n",
    "                              \"rs114376585\" : \"rs3096702\",\n",
    "                              \"rs527588882\" : \"rs9278592\",\n",
    "                              \"rs144721865\" : \"rs9368661\",\n",
    "                              \"rs572291073\" : \"rs2571388\",\n",
    "                              \"rs376201080\" : \"rs142474496\",\n",
    "                              \"rs34948850\" : \"rs10688614\",\n",
    "                              \"rs397887654\" : \"rs36076724\",\n",
    "                              \"rs114473420\" : \"rs3135340\",\n",
    "                              \"rs371043306\" : \"rs145380596\",\n",
    "                              \"rs572943237\" : \"rs11421756\",\n",
    "                              \"rs139078838\" : \"rs9501073\",\n",
    "                              \"rs539183916\" : \"rs2437062\",\n",
    "                              \"rs386410791\" : \"rs141020575\",\n",
    "                              \"rs141507970\" : \"rs9267919\",\n",
    "                              \"rs397823414\" : \"rs35850123\",\n",
    "                              \"rs63475060\" : \"rs5875246\",\n",
    "                              \"rs139104997\" : \"rs9261481\",\n",
    "                              \"rs150282463\" : \"rs13137700\",\n",
    "                              \"rs143466021\" : \"rs9269108\",\n",
    "                              \"rs5875234\" : \"rs3058350\"\n",
    "                             }\n",
    "\n",
    "not_found_dbsnp = {\"rs77010356\", \"rs60284051\", \"rs563604877\"}\n",
    "\n",
    "# Strip whitespaces\n",
    "farashi[\"SNP ID\"] = farashi[\"SNP ID\"].replace(snp_replacement_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "farashi[\"GWAS/eQTL p-value¥\"][(farashi[\"GWAS/eQTL p-value¥\"].isin([\"_\", \"*\"])) | farashi[\"GWAS/eQTL p-value¥\"].isna()] = 0.99\n",
    "\n",
    "farashi[\"GWAS/eQTL p-value¥\"] = farashi[\"GWAS/eQTL p-value¥\"].apply(lambda x: x.replace(\"E\", \"e\") if type(x) is str else x)\n",
    "farashi[\"GWAS/eQTL p-value¥\"] = farashi[\"GWAS/eQTL p-value¥\"].apply(lambda x: x.replace(\"-\", \"-\") if type(x) is str else x)\n",
    "farashi[\"GWAS/eQTL p-value¥\"] = farashi[\"GWAS/eQTL p-value¥\"].apply(lambda x: x.replace(\"−\", \"-\") if type(x) is str else x)\n",
    "\n",
    "farashi[\"GWAS/eQTL p-value¥\"].replace({\"6.11.e - 10 \" : \"6.11e-10\",\n",
    "                                       \"4.65.e - 10 \" : \"4.65e-10\",\n",
    "                                       \"2.42.e - 10 \" : \"2.42e-10\",\n",
    "                                       \"9.4027e–09\" : '9.4027e-09',\n",
    "                                       \"0.01–0.0009\" : \"0.0009\"}, inplace = True)\n",
    "\n",
    "farashi[\"GWAS/eQTL p-value¥\"] = farashi[\"GWAS/eQTL p-value¥\"].apply(lambda x: x.replace(\",\", \";\") if type(x) is str else x)\n",
    "farashi[\"GWAS/eQTL p-value¥\"] = farashi[\"GWAS/eQTL p-value¥\"].apply(lambda x: x.split(\";\") if type(x) is str else x)\n",
    "farashi[\"GWAS/eQTL p-value¥\"] = farashi[\"GWAS/eQTL p-value¥\"].apply(lambda x: min(x) if type(x) is list else x)\n",
    "farashi[\"GWAS/eQTL p-value¥\"] = farashi[\"GWAS/eQTL p-value¥\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-1000...done.\n",
      "querying 1001-1139...done.\n",
      "Finished.\n",
      "482 input query terms found dup hits:\n",
      "\t[('rs77560449', 3), ('rs4682495', 3), ('rs9364535', 2), ('rs742136', 2), ('rs12198152', 2), ('rs6688\n",
      "3 input query terms found no hit:\n",
      "\t['rs60284051', 'rs77010356', 'rs563604877']\n",
      "PASSED: Only known SNPs missing\n"
     ]
    }
   ],
   "source": [
    "# Get the SNP properties from dbsnp\n",
    "import myvariant\n",
    "mv = myvariant.MyVariantInfo()\n",
    "   \n",
    "dbsnp = mv.querymany(list(set(farashi[\"SNP ID\"])), scopes='dbsnp.rsid', fields='dbsnp', returnall = True)\n",
    "print(\"PASSED: Only known SNPs missing\") if not_found_dbsnp == set(dbsnp[\"missing\"]) else print(\"ERROR: New SNPs missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dbSNP data with the reference set\n",
    "dbsnp_tab = pd.DataFrame(dbsnp[\"out\"])\n",
    "\n",
    "# Drop the rs ids that were not found\n",
    "dbsnp_tab.drop(dbsnp_tab[dbsnp_tab[\"notfound\"] == True].index, inplace = True)\n",
    "\n",
    "dbsnp_tab[\"chromosome\"] = dbsnp_tab[\"dbsnp\"].apply(lambda x: x[\"chrom\"])\n",
    "dbsnp_tab[\"location\"] = dbsnp_tab[\"dbsnp\"].apply(lambda x: x[\"hg19\"][\"start\"] if \"hg19\" in x.keys() else None)\n",
    "dbsnp_tab[\"ref\"] = dbsnp_tab[\"dbsnp\"].apply(lambda x: x[\"ref\"])\n",
    "dbsnp_tab[\"alt\"] = dbsnp_tab[\"dbsnp\"].apply(lambda x: x[\"alt\"])\n",
    "\n",
    "# Drop entries that do not have a chromosome location\n",
    "dbsnp_tab.drop(dbsnp_tab[dbsnp_tab[\"location\"].isnull()].index, inplace = True)\n",
    "dbsnp_tab[\"location\"] = dbsnp_tab[\"location\"].astype(int)\n",
    "\n",
    "positives = farashi.merge(dbsnp_tab[[\"query\", \"chromosome\", \"location\", \"ref\", \"alt\"]], how = \"inner\", left_on = \"SNP ID\", right_on = \"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries that are based on a single eQTL study, or that are found in the exon/coding region\n",
    "Dadaev = [\"Dadaev T. et al. 2018\", \"Dadaev T. et al.\"]\n",
    "coding_snps = [\"Coding region\", \"exonic\"]\n",
    "\n",
    "positives = positives[(~positives[\"SNP's Genomic Location\"].isin(coding_snps))]\n",
    "positives = positives[(~positives[\"reference\"].isin(Dadaev))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the gene expression data\n",
    "cols = pd.read_csv(\"../Gene expression data/design_matrix_prostate_unpaired.txt\", delimiter = \"\\t\")\n",
    "reads = pd.read_csv(\"../Gene expression data/expression_matrix_prostate_clean.txt\", delimiter = \"\\t\")\n",
    "# Read in the differential expression calculations\n",
    "dex = pd.read_csv(\"../Gene expression data/Galaxy37-[edgeR_DGE_on_2__design_matrix_prostate_unpaired.txt_-_differentially_expressed_genes].tabular.annotated.txt\", \n",
    "                  delimiter = \"\\t\", index_col = 0, names = [\"ENSEMBL\", \"gene\", \"logFC\", \"logCPM\", \"LR\", \"pValue\", \"FDR\"], header = 0)\n",
    "dex[\"ENSEMBL\"].replace(\"(\\.\\d+)\", \"\", regex = True, inplace = True)\n",
    "# We know that the logFC is a 2 log. However, I prefer absolute values rather than logs\n",
    "dex[\"FC\"] = 2**dex[\"logFC\"]\n",
    "\n",
    "# Assign differential expression to the genes based on the previously set parameters\n",
    "dex[\"Diff expression\"] = \"Unchanged\"\n",
    "dex.loc[(dex[\"FDR\"] <= FDR_cutoff) & (dex[\"FC\"] <= 1/FC_cutoff), \"Diff expression\"] = \"Underexpressed\"\n",
    "dex.loc[(dex[\"FDR\"] <= FDR_cutoff) & (dex[\"FC\"] >= FC_cutoff), \"Diff expression\"] = \"Overexpressed\"\n",
    "\n",
    "# Get the raw reads data\n",
    "reads[\"total\"] = reads.sum(axis = 1, numeric_only = True)\n",
    "reads[\"freq\"] = ((reads[list(cols[\"samplename\"])] > 0) * 1).sum(axis = 1)\n",
    "reads[\"gene_ids\"].replace(\"(\\.\\d+)\", \"\", regex = True, inplace = True)\n",
    "\n",
    "reads = reads.merge(dex, left_on = \"gene_ids\", right_on = \"ENSEMBL\", how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the connection to the database (first time you may have to run ensembl.download() and ensembl.index())\n",
    "# To align with our reference set, we take a Ensembl version from 2019\n",
    "from pyensembl import EnsemblRelease\n",
    "ensembl = EnsemblRelease(92)\n",
    "\n",
    "# Function to extract the data (and prevent superfluous queries)\n",
    "def getEnsemblData(id):\n",
    "    try:\n",
    "        data = ensembl.gene_by_id(id)\n",
    "        return pd.Series({\"gene name\" : data.gene_name, \n",
    "                          \"chromosome\" : data.contig, \n",
    "                          \"gene start\" : data.start,\n",
    "                          \"gene stop\" : data.end,\n",
    "                          \"protein_coding\" : data.is_protein_coding})\n",
    "    except ValueError:\n",
    "        return pd.Series({\"gene name\" : None, \n",
    "                          \"chromosome\" : None, \n",
    "                          \"gene start\" : None,\n",
    "                          \"gene stop\" : None,\n",
    "                          \"protein_coding\" : None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the postifxes of the gene identifiers\n",
    "reads[\"gene_ids\"].replace(\"\\.\\d+\", \"\", regex = True, inplace = True)\n",
    "reads[[\"gene name\", \"chromosome\", \"gene start\", \"gene stop\", \"protein_coding\"]] = reads[\"gene_ids\"].apply(lambda x: getEnsemblData(x))\n",
    "\n",
    "# Replace some of the gene names with the updated ones\n",
    "reads[\"gene name\"].replace(gene_replacement_dictionary, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: Only known missing genes absent in gene expression data\n"
     ]
    }
   ],
   "source": [
    "# Check whether all genes in the reference set are in the expression data\n",
    "known_missing_from_reads = {'LOC284581', 'MFSD4A-AS1'}\n",
    "\n",
    "print(\"PASSED: Only known missing genes absent in gene expression data\") if set(positives[\"gene\"]) - set(reads[\"gene name\"]) == known_missing_from_reads else print(\"Failed: New missing entries found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PathwayStudio primarily contains protein coding gene entries. All non-protein coding entries are therefore removed\n",
    "reads = reads[reads[\"protein_coding\"] == True]\n",
    "\n",
    "# Drop the mitochondrial genes and the entries that could not be found\n",
    "reads.drop(reads[reads[\"chromosome\"].isin([\"MT\", None])].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of the exon\n",
    "exons = pd.DataFrame([x.to_dict() for x in ensembl.exons()])\n",
    "exons[\"exon length\"] = (exons[\"end\"] - exons[\"start\"]) + 1\n",
    "exon_length = exons.groupby(\"gene_id\").sum()\n",
    "\n",
    "reads = reads.merge(exon_length[\"exon length\"], how = \"left\", left_on = \"gene_ids\", right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of all combinations of SNPs and genes that are on the same chromosome\n",
    "positives[\"location\"] = positives[\"location\"].astype(int)\n",
    "snp_candidates = positives[[\"SNP ID\", \"chromosome\", \"location\", \"gene\", \"SNP's Genomic Location\", \"GWAS/eQTL p-value¥\"]].merge(\n",
    "    reads[[\"gene_ids\", \"gene name\", \"chromosome\", \"gene start\", \"gene stop\", \"exon length\", \"FC\", \"FDR\", \"Diff expression\"]], on = \"chromosome\", how = \"inner\")\n",
    "\n",
    "# Drop all entries that do not describe an unique pair of SNP and gene.\n",
    "# If gene start/stop would also be used to determine duplicates, at most 57 extra entries would be found. \n",
    "# This number is considered to be insignificant.\n",
    "snp_candidates.drop_duplicates([\"SNP ID\", \"gene name\"], keep = \"last\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the pairs where the SNP window and the gene windows overlap\n",
    "snp_candidates[\"candidate\"] = snp_candidates.apply(lambda x: True if ((x[\"gene stop\"] >= x[\"location\"] - max_distance and x[\"gene stop\"] <= x[\"location\"] + max_distance) or \n",
    "                                                                      (x[\"gene start\"] >= x[\"location\"] - max_distance and x[\"gene start\"] <= x[\"location\"] + max_distance)) else False, axis = 1)\n",
    "\n",
    "# Without any distance filter, there are 244 unique SNP-gene pairs\n",
    "if distance_filter:\n",
    "    snp_candidates.drop(snp_candidates[snp_candidates[\"candidate\"] == False].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the entries in the SNP candidates as positives. Also remove all duplicate SNP-gene entries.\n",
    "positives[\"Class\"] = 1\n",
    "positives.drop_duplicates([\"SNP ID\", \"gene\"], keep = \"last\", inplace = True)\n",
    "\n",
    "# Assign reference to set\n",
    "f = snp_candidates.drop(columns = [\"gene\", \"candidate\"]).merge(positives[[\"Class\", \"SNP ID\", \"gene\"]], how = \"left\", left_on = [\"SNP ID\", \"gene name\"], right_on = [\"SNP ID\", \"gene\"])\n",
    "f[\"Class\"].fillna(value = 0, inplace = True)\n",
    "f[\"Class\"] = f[\"Class\"].astype(int)\n",
    "\n",
    "# Also removed a column that was only used for merging.\n",
    "f.drop(columns = \"gene\", inplace = True)\n",
    "\n",
    "# Drop all entries that don't have at least one positive case\n",
    "f = f[f[\"SNP ID\"].isin(f[\"SNP ID\"][f[\"Class\"] == True])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between the gene and the SNP\n",
    "f[[\"gene start\", \"gene stop\"]] = f[[\"gene start\", \"gene stop\"]].astype(int)\n",
    "f[\"bp distance absolute\"] = f.apply(lambda x: min([abs(x[\"gene start\"] - x[\"location\"]), abs(x[\"gene stop\"] - x[\"location\"])]), axis = 1).astype(int)\n",
    "f[\"bp distance\"] = f.apply(lambda x: min([x[\"gene start\"] - x[\"location\"], x[\"gene stop\"] - x[\"location\"]], key = abs), axis = 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rank of the gene as compared to other genes\n",
    "f = f.sort_values([\"SNP ID\", \"bp distance absolute\"])\n",
    "f[\"Gene rank\"] = f.groupby(\"SNP ID\").cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(f[\"Class\"], -f[\"Gene rank\"], pos_label = 1)\n",
    "print(sklearn.metrics.auc(fpr, tpr) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNPS2 = list(set(f_out[\"SNP ID\"]))\n",
    "aucs = []\n",
    "for snp in SNPS2:\n",
    "  fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcomes[\"reference\"][outcomes[\"snp\"] == snp], -outcomes[\"rank for SNP\"][outcomes[\"snp\"] == snp], pos_label = 1)\n",
    "  aucs.append(sklearn.metrics.auc(fpr, tpr))\n",
    "print(sum(aucs)/len(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.drop(columns = [\"gene start\", \"gene stop\"], inplace = True)\n",
    "f_backup = f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv(\"Farashi full 2000000 bp distance no pvalue filtering.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f[f[\"bp distance absolute\"] <= 1000000]\n",
    "snpsums = f.groupby(\"SNP ID\")[\"Class\"].sum()\n",
    "f = f[f[\"SNP ID\"].isin(list(snpsums[snpsums > 0].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv(\"Farashi full 1000000 bp distance no pvalue filtering.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f[f[\"bp distance absolute\"] <= 100000]\n",
    "snpsums = f.groupby(\"SNP ID\")[\"Class\"].sum()\n",
    "f = f[f[\"SNP ID\"].isin(list(snpsums[snpsums > 0].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv(\"Farashi full 100000 bp distance no pvalue filtering.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f_backup\n",
    "f = f[f[\"GWAS/eQTL p-value¥\"] <= 0.00000005]\n",
    "snpsums = f.groupby(\"SNP ID\")[\"Class\"].sum()\n",
    "f = f[f[\"SNP ID\"].isin(list(snpsums[snpsums > 0].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv(\"Farashi full 2000000 bp distance pvalue filtering.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
