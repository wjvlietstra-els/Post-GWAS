{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2vec classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Autoencoder code staat hier, maar zelf ff herschrijven\n",
    "# https://github.com/MedicineBiology-AI/N2A-SVM/blob/master/Autoencoder/MyAE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_type = \"combi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "if class_type == \"normal\":\n",
    "    f = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Node2vec/directed_weighed_complete.emb\", sep = \" \", skiprows = 1, header = None, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoencoded embeddings\n",
    "if class_type == \"autoencode\":\n",
    "    f = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Node2vec/autorcode_emb.txt\", sep = \"\\t\", header = None)\n",
    "    f.drop(columns = [350], inplace = True)\n",
    "    f2 = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Node2vec/directed_weighed_complete.emb\", sep = \" \", skiprows = 1, header = None, index_col = 0)\n",
    "    f.index = f2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend embeddings with graphlets\n",
    "if class_type == \"graphlet\":\n",
    "    f = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Node2vec/directed_weighed_complete.emb\", sep = \" \", skiprows = 1, header = None, index_col = 0)\n",
    "    graphlets = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/EVOKE/unfiltered.txt\", header = None, sep = \" \", skiprows = 1)\n",
    "    graphlets.drop(columns = [73], inplace = True)\n",
    "    graphlets = graphlets.apply(lambda x: np.log10(x, where = x > 0))\n",
    "    graphlets.columns = [\"Graphlet \" + str(x) for x in range(len(list(graphlets)))]\n",
    "    graphlets.index = [x + 1 for x in list(graphlets.index)]\n",
    "    f = f.merge(graphlets, right_index = True, left_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if class_type == \"combi\":\n",
    "    f = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Node2vec/autorcode_emb.txt\", sep = \"\\t\", header = None)\n",
    "    f.drop(columns = [350], inplace = True)\n",
    "    f2 = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Node2vec/directed_weighed_complete.emb\", sep = \" \", skiprows = 1, header = None, index_col = 0)\n",
    "    f.index = f2.index\n",
    "    graphlets = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/EVOKE/unfiltered.txt\", header = None, sep = \" \", skiprows = 1)\n",
    "    graphlets.drop(columns = [73], inplace = True)\n",
    "    graphlets = graphlets.apply(lambda x: np.log10(x, where = x > 0))\n",
    "    graphlets.columns = [\"Graphlet \" + str(x) for x in range(len(list(graphlets)))]\n",
    "    graphlets.index = [x + 1 for x in list(graphlets.index)]\n",
    "    f = f.merge(graphlets, right_index = True, left_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reference set\n",
    "ref = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Input sets/Farashi/Farashi full 2000000 bp distance no pvalue filtering.csv\")\n",
    "\n",
    "# Load the mapping file\n",
    "with open(\"/Users/vlietstraw/git/Post-GWAS/ENSEMBL_mappings.json\", \"r\") as fp:\n",
    "    ensembl_dict = json.load(fp)\n",
    "ref[\"nodeID\"] = [ensembl_dict[x] if x in ensembl_dict.keys() else None for x in ref[\"gene_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all unmappable candidates\n",
    "ref.dropna(subset = [\"nodeID\"], inplace = True)\n",
    "ref[\"nodeID\"] = ref[\"nodeID\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bp distance cutoff\n",
    "max_bp_distance = 2000\n",
    "max_bp_distance = max_bp_distance * 1000\n",
    "ref = ref[ref[\"bp distance absolute\"] <= max_bp_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all SNPs which no longer have a positive case\n",
    "pos_counts = ref.groupby(\"SNP ID\")[\"Class\"].sum()\n",
    "ref = ref[~ref[\"SNP ID\"].isin(pos_counts[pos_counts == 0].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all genes which are at least once positive\n",
    "positives = ref.groupby(\"nodeID\")[\"Class\"].sum()\n",
    "positives[positives > 1] = 1\n",
    "\n",
    "f = f.merge(positives, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave SNP out classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = pd.DataFrame()\n",
    "train_auc_score = []\n",
    "train_auc_rank = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform leave-SNP-out cross validation\n",
    "SNPs = list(set(ref[\"SNP ID\"]))\n",
    "for snp in SNPs:\n",
    "    print(\"Predicting candidates for \" + snp + \", number \" + str(SNPs.index(snp) + 1) + \" out of \" + str(len(SNPs)))\n",
    "\n",
    "    f_test = f[f.index.isin(ref[ref[\"SNP ID\"] == snp][\"nodeID\"])].copy()\n",
    "    f_train = f[f.index.isin(ref[ref[\"SNP ID\"] != snp][\"nodeID\"])].copy()\n",
    "    \n",
    "    train_class = f[\"Class\"][f.index.isin(f_train.index)]\n",
    "    test_class = f[\"Class\"][f.index.isin(f_test.index)]\n",
    "    \n",
    "    f_test.drop(columns = [\"Class\"], inplace = True)\n",
    "    f_train.drop(columns = [\"Class\"], inplace = True)\n",
    "\n",
    "    #clf = KNeighborsClassifier(n_neighbors = 9)\n",
    "    #clf = LogisticRegression(n_jobs = -1)\n",
    "    clf = SVR(gamma=\"auto\")\n",
    "    \n",
    "    clf.fit(f_train, train_class)\n",
    "\n",
    "    outcomes = pd.concat([outcomes, pd.DataFrame({\"predicted\" : clf.predict(f_test), \n",
    "                                                    \"SNP ID\" : snp,\n",
    "                                                    \"nodeID\" : f_test.index})])\n",
    "    \n",
    "outcomes = outcomes.merge(ref[[\"SNP ID\", \"nodeID\", \"Class\"]], on = [\"SNP ID\", \"nodeID\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave chromosome out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes2 = pd.DataFrame()\n",
    "train_auc_score2 = []\n",
    "train_auc_rank2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting candidates for chromosome 19\n",
      "Predicting candidates for chromosome X\n",
      "Predicting candidates for chromosome 16\n",
      "Predicting candidates for chromosome 5\n",
      "Predicting candidates for chromosome 20\n",
      "Predicting candidates for chromosome 9\n",
      "Predicting candidates for chromosome 22\n",
      "Predicting candidates for chromosome 11\n",
      "Predicting candidates for chromosome 10\n",
      "Predicting candidates for chromosome 3\n",
      "Predicting candidates for chromosome 1\n",
      "Predicting candidates for chromosome 2\n",
      "Predicting candidates for chromosome 17\n",
      "Predicting candidates for chromosome 21\n",
      "Predicting candidates for chromosome 6\n",
      "Predicting candidates for chromosome 13\n",
      "Predicting candidates for chromosome 4\n",
      "Predicting candidates for chromosome 7\n",
      "Predicting candidates for chromosome 14\n",
      "Predicting candidates for chromosome 12\n",
      "Predicting candidates for chromosome 8\n"
     ]
    }
   ],
   "source": [
    "# Perform leave-SNP-out cross validation\n",
    "chromosomes = list(set(ref[\"chromosome\"]))\n",
    "\n",
    "for chrom in chromosomes:\n",
    "    print(\"Predicting candidates for chromosome \" + chrom)\n",
    "\n",
    "    f_test = f[f.index.isin(ref[\"nodeID\"][ref[\"chromosome\"] == chrom])].copy()\n",
    "    f_train = f[f.index.isin(ref[\"nodeID\"][ref[\"chromosome\"] != chrom])].copy()\n",
    "    \n",
    "    train_class = f[\"Class\"][f.index.isin(f_train.index)]\n",
    "    test_class = f[\"Class\"][f.index.isin(f_test.index)]\n",
    "    \n",
    "    f_test.drop(columns = [\"Class\"], inplace = True)\n",
    "    f_train.drop(columns = [\"Class\"], inplace = True)\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors = 9)\n",
    "    #clf = LogisticRegression(n_jobs = -1, max_iter = 100000)\n",
    "    #clf = SVR(gamma=\"auto\")\n",
    "    #clf = DecisionTreeRegressor()\n",
    "    \n",
    "    clf.fit(np.array(f_train), np.array(train_class))\n",
    "\n",
    "    outcomes2 = pd.concat([outcomes2, pd.DataFrame({\"predicted\" : clf.predict_proba(f_test)[:,1],\n",
    "                                                    \"Class\" : test_class, \n",
    "                                                    \"chromosome\" : chrom,\n",
    "                                                    \"nodeID\" : f_test.index})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.to_csv(\"/Users/vlietstraw/git/Post-GWAS/Node2vec/Leave-SNP-Out cross validation \" + class_type + \" \" + str(max_bp_distance) + \".csv\", index = False)\n",
    "outcomes2.to_csv(\"/Users/vlietstraw/git/Post-GWAS/Node2vec/Leave-chromosome-Out cross validation \" + class_type + \" \" + str(max_bp_distance) + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate leave-SNP-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = outcomes.sort_values([\"SNP ID\", \"predicted\"], ascending = False)\n",
    "outcomes[\"For-SNP rank\"] = outcomes.groupby(\"SNP ID\").cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(outcomes[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(outcomes[\"SNP ID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcomes[\"Class\"], -outcomes[\"For-SNP rank\"], pos_label = 1)\n",
    "print(sklearn.metrics.auc(fpr, tpr) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ROC-AUC for every SNP and average the result\n",
    "SNPS2 = list(set(outcomes[\"SNP ID\"]))\n",
    "aucs = []\n",
    "for snp in SNPS2:\n",
    "  if len(set(outcomes[\"Class\"][outcomes[\"SNP ID\"] == snp])) == 1:\n",
    "      aucs.append(list(set(outcomes[\"Class\"][outcomes[\"SNP ID\"] == snp]))[0])\n",
    "  else:\n",
    "      fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcomes[\"Class\"][outcomes[\"SNP ID\"] == snp], -outcomes[\"For-SNP rank\"][outcomes[\"SNP ID\"] == snp], pos_label = 1)\n",
    "      aucs.append(sklearn.metrics.auc(fpr, tpr))\n",
    "print(sum(aucs)/len(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hits @1\n",
    "sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hits @3\n",
    "sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] <= 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hits @5\n",
    "sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] <= 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hits @10\n",
    "sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] <= 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes[\"For-SNP rank\"][(outcomes[\"Class\"] == 1)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes[\"For-SNP rank\"][outcomes[\"Class\"] == 1].quantile(q = [0,0.25,0.5,0.75,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate leave-chromosome-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes2 = outcomes2.sort_values([\"chromosome\", \"predicted\"], ascending = False)\n",
    "outcomes2[\"For-chromosome rank\"] = outcomes2.groupby(\"chromosome\").cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosomes = list(set(outcomes2[\"chromosome\"]))\n",
    "aucs = []\n",
    "for chrom in chromosomes:\n",
    "  fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcomes2[\"Class\"][outcomes2[\"chromosome\"] == chrom], -outcomes2[\"For-chromosome rank\"][outcomes2[\"chromosome\"] == chrom], pos_label = 1)\n",
    "  aucs.append(sklearn.metrics.auc(fpr, tpr))\n",
    "print(sum(aucs)/len(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = ref.merge(outcomes2[[\"nodeID\", \"predicted\"]], on = \"nodeID\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = ref.sort_values([\"SNP ID\", \"predicted\"], ascending = False)\n",
    "ref[\"For-SNP rank\"] = ref.groupby(\"SNP ID\").cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(ref[\"Class\"], -ref[\"For-SNP rank\"], pos_label = 1)\n",
    "print(sklearn.metrics.auc(fpr, tpr) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ROC-AUC for every SNP and average the result\n",
    "SNPS2 = list(set(ref[\"SNP ID\"]))\n",
    "aucs = []\n",
    "for snp in SNPS2:\n",
    "  if len(set(ref[\"Class\"][ref[\"SNP ID\"] == snp])) == 1:\n",
    "      aucs.append(list(set(ref[\"Class\"][ref[\"SNP ID\"] == snp]))[0])\n",
    "  else:\n",
    "      fpr, tpr, thresholds = sklearn.metrics.roc_curve(ref[\"Class\"][ref[\"SNP ID\"] == snp], -ref[\"For-SNP rank\"][ref[\"SNP ID\"] == snp], pos_label = 1)\n",
    "      aucs.append(sklearn.metrics.auc(fpr, tpr))\n",
    "print(sum(aucs)/len(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hits @1\n",
    "sum(ref[\"Class\"][(ref[\"Class\"] == 1) & (ref[\"For-SNP rank\"] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hits @3\n",
    "sum(ref[\"Class\"][(ref[\"Class\"] == 1) & (ref[\"For-SNP rank\"] <= 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hits @5\n",
    "sum(ref[\"Class\"][(ref[\"Class\"] == 1) & (ref[\"For-SNP rank\"] <= 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hits @10\n",
    "sum(ref[\"Class\"][(ref[\"Class\"] == 1) & (ref[\"For-SNP rank\"] <= 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref[\"For-SNP rank\"][(ref[\"Class\"] == 1)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref[\"For-SNP rank\"][ref[\"Class\"] == 1].quantile(q = [0,0.25,0.5,0.75,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
