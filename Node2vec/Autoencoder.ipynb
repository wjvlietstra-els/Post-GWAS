{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as prep\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(object):\n",
    "    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus,\n",
    "                 optimizer = tf.train.AdamOptimizer(), scale = 0.0):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.transfer = transfer_function\n",
    "        self.scale = tf.placeholder(tf.float32)\n",
    "        self.training_scale = scale\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights\n",
    "        self.x = tf.placeholder(tf.float32,[None, self.n_input])\n",
    "        self.hidden = self.transfer(tf.add(tf.matmul(self.x + scale * tf.random_normal((n_input,)),\n",
    "                                                     self.weights['w1']), self.weights['b1']))\n",
    "        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']),self.weights['b2'])\n",
    "        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.Variable(xavier_init(self.n_input, self.n_hidden))\n",
    "        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden],dtype= tf.float32))\n",
    "        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype= tf.float32))\n",
    "        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype= tf.float32))\n",
    "        return all_weights\n",
    "    def partial_fit(self,X ):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict= {self.x: X,\n",
    "                                                                           self.scale: self.training_scale})\n",
    "        return cost\n",
    "    def before_loss(self, X):\n",
    "        cost = self.sess.run((self.cost), feed_dict={self.x: X,\n",
    "                                                                          self.scale: self.training_scale})\n",
    "        return cost\n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.hidden, feed_dict= {self.x : X, self.scale: self.training_scale})\n",
    "    def generate(self, hidden = None):\n",
    "        if hidden is None:\n",
    "            #print(self.weights[\"b1\"].shape)\n",
    "            hidden = np.random.normal( size = self.weights[\"b1\"])\n",
    "            #hidden = np.random.normal(size=self.weights[\"b1\"].shape)\n",
    "\n",
    "\n",
    "        return self.sess.run(self.reconstruction, feed_dict= {self.hidden: hidden})\n",
    "    ###这块的reconstruction是初始化定义的w* x + b\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        ##这块的重建是指整体运行一边复原过程\n",
    "        return self.sess.run(self.reconstruction, feed_dict={self.x : X, self.scale: self.training_scale})\n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'])\n",
    "    def getBias(self):\n",
    "        return self.sess.run(self.weights['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=open(\"autorcode_emb.txt\",\"w\")\n",
    "file2=open(\"gene.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(X_train):\n",
    "    preprocessor = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    return X_train\n",
    "\n",
    "def get_random_block_from_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index: (start_index + batch_size)]\n",
    "\n",
    "def xavier_init(fan_in, fan_out, constant = 1):\n",
    "    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), minval = low, maxval = high, dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneSet=set()\n",
    "data=[]\n",
    "for lines in open(r\"/Users/vlietstraw/git/Post-GWAS/Node2vec/directed_weighed_complete_copy_for_autoencoder.emb\",\"r\"):\n",
    "    line=lines.strip().split()\n",
    "    geneSet.add(line[0])\n",
    "    file2.write(line[0])\n",
    "    file2.write(\"\\n\")\n",
    "    list1=[]\n",
    "    for l in line[1:]:\n",
    "        list1.append(float(l))\n",
    "    data.append(list1)\n",
    "#print (geneSet)\n",
    "#print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/envs/SNP-gene/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "training_epochs =1000\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "input_n_size = [128, 256]\n",
    "hidden_size = [350, 100]\n",
    "sdne = []\n",
    "\n",
    "for i in range(1):\n",
    "    if i== 0:\n",
    "        ae = Autoencoder(n_input = input_n_size[0], n_hidden = hidden_size[0], transfer_function = tf.nn.elu,\n",
    "                             optimizer = tf.train.AdamOptimizer(learning_rate= 0.0001),\n",
    "                             scale = 0)\n",
    "        \n",
    "        sdne.append(ae)\n",
    "    else:\n",
    "        ae = Autoencoder(n_input = input_n_size[1], n_hidden = hidden_size[1], transfer_function = tf.nn.sigmoid,\n",
    "                             optimizer = tf.train.AdagradOptimizer(learning_rate= 0.01),\n",
    "                             scale = 0)\n",
    "        \n",
    "        sdne.append(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 每个样本上的误差: 79.398108989\n",
      "Epoch:    2 每个样本上的误差: 56.525825149\n",
      "Epoch:    3 每个样本上的误差: 46.475921674\n",
      "Epoch:    4 每个样本上的误差: 42.626154560\n",
      "Epoch:    5 每个样本上的误差: 27.279527617\n",
      "Epoch:    6 每个样本上的误差: 23.249182481\n",
      "Epoch:    7 每个样本上的误差: 19.209487937\n",
      "Epoch:    8 每个样本上的误差: 17.712815232\n",
      "Epoch:    9 每个样本上的误差: 21.009118150\n",
      "Epoch:   10 每个样本上的误差: 19.348768034\n",
      "Epoch:   11 每个样本上的误差: 12.194838732\n",
      "Epoch:   12 每个样本上的误差: 12.240765778\n",
      "Epoch:   13 每个样本上的误差: 11.847535212\n",
      "Epoch:   14 每个样本上的误差: 9.544716777\n",
      "Epoch:   15 每个样本上的误差: 10.280545644\n",
      "Epoch:   16 每个样本上的误差: 8.877107819\n",
      "Epoch:   17 每个样本上的误差: 7.647968028\n",
      "Epoch:   18 每个样本上的误差: 6.489051672\n",
      "Epoch:   19 每个样本上的误差: 8.066670661\n",
      "Epoch:   20 每个样本上的误差: 3.591215888\n",
      "Epoch:   21 每个样本上的误差: 6.840368264\n",
      "Epoch:   22 每个样本上的误差: 4.486811848\n",
      "Epoch:   23 每个样本上的误差: 3.725745437\n",
      "Epoch:   24 每个样本上的误差: 4.207976084\n",
      "Epoch:   25 每个样本上的误差: 5.283438412\n",
      "Epoch:   26 每个样本上的误差: 4.270611854\n",
      "Epoch:   27 每个样本上的误差: 3.925184639\n",
      "Epoch:   28 每个样本上的误差: 3.148459039\n",
      "Epoch:   29 每个样本上的误差: 3.000770291\n",
      "Epoch:   30 每个样本上的误差: 3.266325861\n",
      "Epoch:   31 每个样本上的误差: 2.276787346\n",
      "Epoch:   32 每个样本上的误差: 2.138447677\n",
      "Epoch:   33 每个样本上的误差: 2.738711794\n",
      "Epoch:   34 每个样本上的误差: 2.411264319\n",
      "Epoch:   35 每个样本上的误差: 1.955409026\n",
      "Epoch:   36 每个样本上的误差: 1.909564993\n",
      "Epoch:   37 每个样本上的误差: 1.847255144\n",
      "Epoch:   38 每个样本上的误差: 2.346505042\n",
      "Epoch:   39 每个样本上的误差: 2.184970289\n",
      "Epoch:   40 每个样本上的误差: 1.967927883\n",
      "Epoch:   41 每个样本上的误差: 1.396428938\n",
      "Epoch:   42 每个样本上的误差: 1.515472476\n",
      "Epoch:   43 每个样本上的误差: 1.304488964\n",
      "Epoch:   44 每个样本上的误差: 1.452585969\n",
      "Epoch:   45 每个样本上的误差: 1.203914636\n",
      "Epoch:   46 每个样本上的误差: 1.660752684\n",
      "Epoch:   47 每个样本上的误差: 1.178029688\n",
      "Epoch:   48 每个样本上的误差: 1.225051715\n",
      "Epoch:   49 每个样本上的误差: 1.219530621\n",
      "Epoch:   50 每个样本上的误差: 0.891057683\n",
      "Epoch:   51 每个样本上的误差: 0.993816277\n",
      "Epoch:   52 每个样本上的误差: 1.124386203\n",
      "Epoch:   53 每个样本上的误差: 0.824811470\n",
      "Epoch:   54 每个样本上的误差: 0.882014937\n",
      "Epoch:   55 每个样本上的误差: 1.309629203\n",
      "Epoch:   56 每个样本上的误差: 0.857406170\n",
      "Epoch:   57 每个样本上的误差: 1.018277838\n",
      "Epoch:   58 每个样本上的误差: 0.875122807\n",
      "Epoch:   59 每个样本上的误差: 0.888537568\n",
      "Epoch:   60 每个样本上的误差: 0.887952838\n",
      "Epoch:   61 每个样本上的误差: 0.862770007\n",
      "Epoch:   62 每个样本上的误差: 0.703059462\n",
      "Epoch:   63 每个样本上的误差: 0.669436892\n",
      "Epoch:   64 每个样本上的误差: 0.909147678\n",
      "Epoch:   65 每个样本上的误差: 0.708976736\n",
      "Epoch:   66 每个样本上的误差: 0.722649856\n",
      "Epoch:   67 每个样本上的误差: 0.721726871\n",
      "Epoch:   68 每个样本上的误差: 0.796054614\n",
      "Epoch:   69 每个样本上的误差: 0.757266368\n",
      "Epoch:   70 每个样本上的误差: 0.617879502\n",
      "Epoch:   71 每个样本上的误差: 0.669277567\n",
      "Epoch:   72 每个样本上的误差: 0.815016393\n",
      "Epoch:   73 每个样本上的误差: 0.743363626\n",
      "Epoch:   74 每个样本上的误差: 0.861624051\n",
      "Epoch:   75 每个样本上的误差: 0.738506080\n",
      "Epoch:   76 每个样本上的误差: 0.693129718\n",
      "Epoch:   77 每个样本上的误差: 0.702939630\n",
      "Epoch:   78 每个样本上的误差: 0.711923096\n",
      "Epoch:   79 每个样本上的误差: 0.601014877\n",
      "Epoch:   80 每个样本上的误差: 0.777368298\n",
      "Epoch:   81 每个样本上的误差: 0.678061121\n",
      "Epoch:   82 每个样本上的误差: 0.596367581\n",
      "Epoch:   83 每个样本上的误差: 0.576843041\n",
      "Epoch:   84 每个样本上的误差: 0.552732735\n",
      "Epoch:   85 每个样本上的误差: 0.437921543\n",
      "Epoch:   86 每个样本上的误差: 0.520264757\n",
      "Epoch:   87 每个样本上的误差: 0.440589696\n",
      "Epoch:   88 每个样本上的误差: 0.491064606\n",
      "Epoch:   89 每个样本上的误差: 0.564037166\n",
      "Epoch:   90 每个样本上的误差: 0.576062926\n",
      "Epoch:   91 每个样本上的误差: 0.544556942\n",
      "Epoch:   92 每个样本上的误差: 0.453705753\n",
      "Epoch:   93 每个样本上的误差: 0.418952957\n",
      "Epoch:   94 每个样本上的误差: 0.424270778\n",
      "Epoch:   95 每个样本上的误差: 0.586260360\n",
      "Epoch:   96 每个样本上的误差: 0.491669300\n",
      "Epoch:   97 每个样本上的误差: 0.457997827\n",
      "Epoch:   98 每个样本上的误差: 0.445692881\n",
      "Epoch:   99 每个样本上的误差: 0.445950739\n",
      "Epoch:  100 每个样本上的误差: 0.401838647\n",
      "Epoch:  101 每个样本上的误差: 0.331016862\n",
      "Epoch:  102 每个样本上的误差: 0.458886236\n",
      "Epoch:  103 每个样本上的误差: 0.381842752\n",
      "Epoch:  104 每个样本上的误差: 0.520941762\n",
      "Epoch:  105 每个样本上的误差: 0.361678193\n",
      "Epoch:  106 每个样本上的误差: 0.494536412\n",
      "Epoch:  107 每个样本上的误差: 0.387755162\n",
      "Epoch:  108 每个样本上的误差: 0.356072232\n",
      "Epoch:  109 每个样本上的误差: 0.411303933\n",
      "Epoch:  110 每个样本上的误差: 0.428687878\n",
      "Epoch:  111 每个样本上的误差: 0.379180204\n",
      "Epoch:  112 每个样本上的误差: 0.377736530\n",
      "Epoch:  113 每个样本上的误差: 0.375822639\n",
      "Epoch:  114 每个样本上的误差: 0.335020221\n",
      "Epoch:  115 每个样本上的误差: 0.387104526\n",
      "Epoch:  116 每个样本上的误差: 0.352450114\n",
      "Epoch:  117 每个样本上的误差: 0.322049101\n",
      "Epoch:  118 每个样本上的误差: 0.359072834\n",
      "Epoch:  119 每个样本上的误差: 0.302302568\n",
      "Epoch:  120 每个样本上的误差: 0.367658366\n",
      "Epoch:  121 每个样本上的误差: 0.423591893\n",
      "Epoch:  122 每个样本上的误差: 0.410679966\n",
      "Epoch:  123 每个样本上的误差: 0.383035598\n",
      "Epoch:  124 每个样本上的误差: 0.342957430\n",
      "Epoch:  125 每个样本上的误差: 0.336867339\n",
      "Epoch:  126 每个样本上的误差: 0.363451666\n",
      "Epoch:  127 每个样本上的误差: 0.345642948\n",
      "Epoch:  128 每个样本上的误差: 0.346370027\n",
      "Epoch:  129 每个样本上的误差: 0.319825832\n",
      "Epoch:  130 每个样本上的误差: 0.290082957\n",
      "Epoch:  131 每个样本上的误差: 0.286172458\n",
      "Epoch:  132 每个样本上的误差: 0.264986280\n",
      "Epoch:  133 每个样本上的误差: 0.297782166\n",
      "Epoch:  134 每个样本上的误差: 0.333133433\n",
      "Epoch:  135 每个样本上的误差: 0.321888066\n",
      "Epoch:  136 每个样本上的误差: 0.261106319\n",
      "Epoch:  137 每个样本上的误差: 0.325475848\n",
      "Epoch:  138 每个样本上的误差: 0.318680095\n",
      "Epoch:  139 每个样本上的误差: 0.323659225\n",
      "Epoch:  140 每个样本上的误差: 0.265107698\n",
      "Epoch:  141 每个样本上的误差: 0.230851191\n",
      "Epoch:  142 每个样本上的误差: 0.251205611\n",
      "Epoch:  143 每个样本上的误差: 0.310884371\n",
      "Epoch:  144 每个样本上的误差: 0.300364549\n",
      "Epoch:  145 每个样本上的误差: 0.285505400\n",
      "Epoch:  146 每个样本上的误差: 0.322328798\n",
      "Epoch:  147 每个样本上的误差: 0.284328092\n",
      "Epoch:  148 每个样本上的误差: 0.269815376\n",
      "Epoch:  149 每个样本上的误差: 0.268303384\n",
      "Epoch:  150 每个样本上的误差: 0.248256109\n",
      "Epoch:  151 每个样本上的误差: 0.257006258\n",
      "Epoch:  152 每个样本上的误差: 0.272681799\n",
      "Epoch:  153 每个样本上的误差: 0.234787322\n",
      "Epoch:  154 每个样本上的误差: 0.269258106\n",
      "Epoch:  155 每个样本上的误差: 0.236672206\n",
      "Epoch:  156 每个样本上的误差: 0.232420557\n",
      "Epoch:  157 每个样本上的误差: 0.232509624\n",
      "Epoch:  158 每个样本上的误差: 0.270214926\n",
      "Epoch:  159 每个样本上的误差: 0.222568127\n",
      "Epoch:  160 每个样本上的误差: 0.225141932\n",
      "Epoch:  161 每个样本上的误差: 0.256544869\n",
      "Epoch:  162 每个样本上的误差: 0.206057350\n",
      "Epoch:  163 每个样本上的误差: 0.266499158\n",
      "Epoch:  164 每个样本上的误差: 0.207123719\n",
      "Epoch:  165 每个样本上的误差: 0.263530961\n",
      "Epoch:  166 每个样本上的误差: 0.227555628\n",
      "Epoch:  167 每个样本上的误差: 0.171507006\n",
      "Epoch:  168 每个样本上的误差: 0.196607894\n",
      "Epoch:  169 每个样本上的误差: 0.197630470\n",
      "Epoch:  170 每个样本上的误差: 0.238942027\n",
      "Epoch:  171 每个样本上的误差: 0.222053176\n",
      "Epoch:  172 每个样本上的误差: 0.197246818\n",
      "Epoch:  173 每个样本上的误差: 0.199395635\n",
      "Epoch:  174 每个样本上的误差: 0.177044986\n",
      "Epoch:  175 每个样本上的误差: 0.218560284\n",
      "Epoch:  176 每个样本上的误差: 0.209924475\n",
      "Epoch:  177 每个样本上的误差: 0.250177293\n",
      "Epoch:  178 每个样本上的误差: 0.196378403\n",
      "Epoch:  179 每个样本上的误差: 0.178384412\n",
      "Epoch:  180 每个样本上的误差: 0.169518547\n",
      "Epoch:  181 每个样本上的误差: 0.158096795\n",
      "Epoch:  182 每个样本上的误差: 0.210735373\n",
      "Epoch:  183 每个样本上的误差: 0.198741291\n",
      "Epoch:  184 每个样本上的误差: 0.221238837\n",
      "Epoch:  185 每个样本上的误差: 0.203686522\n",
      "Epoch:  186 每个样本上的误差: 0.173062612\n",
      "Epoch:  187 每个样本上的误差: 0.203759571\n",
      "Epoch:  188 每个样本上的误差: 0.210133533\n",
      "Epoch:  189 每个样本上的误差: 0.201149755\n",
      "Epoch:  190 每个样本上的误差: 0.213395942\n",
      "Epoch:  191 每个样本上的误差: 0.208622923\n",
      "Epoch:  192 每个样本上的误差: 0.191061974\n",
      "Epoch:  193 每个样本上的误差: 0.191887070\n",
      "Epoch:  194 每个样本上的误差: 0.143296213\n",
      "Epoch:  195 每个样本上的误差: 0.201863217\n",
      "Epoch:  196 每个样本上的误差: 0.162270957\n",
      "Epoch:  197 每个样本上的误差: 0.166429643\n",
      "Epoch:  198 每个样本上的误差: 0.174027725\n",
      "Epoch:  199 每个样本上的误差: 0.163214018\n",
      "Epoch:  200 每个样本上的误差: 0.167280814\n",
      "Epoch:  201 每个样本上的误差: 0.164560344\n",
      "Epoch:  202 每个样本上的误差: 0.150213591\n",
      "Epoch:  203 每个样本上的误差: 0.188707795\n",
      "Epoch:  204 每个样本上的误差: 0.143199757\n",
      "Epoch:  205 每个样本上的误差: 0.142707631\n",
      "Epoch:  206 每个样本上的误差: 0.175029956\n",
      "Epoch:  207 每个样本上的误差: 0.160206331\n",
      "Epoch:  208 每个样本上的误差: 0.162522529\n",
      "Epoch:  209 每个样本上的误差: 0.163008274\n",
      "Epoch:  210 每个样本上的误差: 0.142044691\n",
      "Epoch:  211 每个样本上的误差: 0.163266488\n",
      "Epoch:  212 每个样本上的误差: 0.175942029\n",
      "Epoch:  213 每个样本上的误差: 0.171959024\n",
      "Epoch:  214 每个样本上的误差: 0.165657633\n",
      "Epoch:  215 每个样本上的误差: 0.173117058\n",
      "Epoch:  216 每个样本上的误差: 0.156637813\n",
      "Epoch:  217 每个样本上的误差: 0.159063714\n",
      "Epoch:  218 每个样本上的误差: 0.182762876\n",
      "Epoch:  219 每个样本上的误差: 0.136310693\n",
      "Epoch:  220 每个样本上的误差: 0.168350825\n",
      "Epoch:  221 每个样本上的误差: 0.118578278\n",
      "Epoch:  222 每个样本上的误差: 0.151220403\n",
      "Epoch:  223 每个样本上的误差: 0.159139122\n",
      "Epoch:  224 每个样本上的误差: 0.147441259\n",
      "Epoch:  225 每个样本上的误差: 0.154134870\n",
      "Epoch:  226 每个样本上的误差: 0.131314460\n",
      "Epoch:  227 每个样本上的误差: 0.188436356\n",
      "Epoch:  228 每个样本上的误差: 0.190125905\n",
      "Epoch:  229 每个样本上的误差: 0.170076402\n",
      "Epoch:  230 每个样本上的误差: 0.150915520\n",
      "Epoch:  231 每个样本上的误差: 0.130730179\n",
      "Epoch:  232 每个样本上的误差: 0.176785704\n",
      "Epoch:  233 每个样本上的误差: 0.135139724\n",
      "Epoch:  234 每个样本上的误差: 0.147039245\n",
      "Epoch:  235 每个样本上的误差: 0.127792081\n",
      "Epoch:  236 每个样本上的误差: 0.174222474\n",
      "Epoch:  237 每个样本上的误差: 0.151748321\n",
      "Epoch:  238 每个样本上的误差: 0.129536680\n",
      "Epoch:  239 每个样本上的误差: 0.167918173\n",
      "Epoch:  240 每个样本上的误差: 0.155773484\n",
      "Epoch:  241 每个样本上的误差: 0.116933229\n",
      "Epoch:  242 每个样本上的误差: 0.145207827\n",
      "Epoch:  243 每个样本上的误差: 0.117460511\n",
      "Epoch:  244 每个样本上的误差: 0.122325726\n",
      "Epoch:  245 每个样本上的误差: 0.129595150\n",
      "Epoch:  246 每个样本上的误差: 0.156061549\n",
      "Epoch:  247 每个样本上的误差: 0.125806043\n",
      "Epoch:  248 每个样本上的误差: 0.120826221\n",
      "Epoch:  249 每个样本上的误差: 0.151171072\n",
      "Epoch:  250 每个样本上的误差: 0.142935570\n",
      "Epoch:  251 每个样本上的误差: 0.120838869\n",
      "Epoch:  252 每个样本上的误差: 0.101728346\n",
      "Epoch:  253 每个样本上的误差: 0.112346366\n",
      "Epoch:  254 每个样本上的误差: 0.102441319\n",
      "Epoch:  255 每个样本上的误差: 0.136260262\n",
      "Epoch:  256 每个样本上的误差: 0.110814370\n",
      "Epoch:  257 每个样本上的误差: 0.121164752\n",
      "Epoch:  258 每个样本上的误差: 0.134173691\n",
      "Epoch:  259 每个样本上的误差: 0.129275735\n",
      "Epoch:  260 每个样本上的误差: 0.097207132\n",
      "Epoch:  261 每个样本上的误差: 0.113409449\n",
      "Epoch:  262 每个样本上的误差: 0.119772379\n",
      "Epoch:  263 每个样本上的误差: 0.125809317\n",
      "Epoch:  264 每个样本上的误差: 0.113448637\n",
      "Epoch:  265 每个样本上的误差: 0.109588300\n",
      "Epoch:  266 每个样本上的误差: 0.139308322\n",
      "Epoch:  267 每个样本上的误差: 0.124436016\n",
      "Epoch:  268 每个样本上的误差: 0.149332830\n",
      "Epoch:  269 每个样本上的误差: 0.126334688\n",
      "Epoch:  270 每个样本上的误差: 0.120078375\n",
      "Epoch:  271 每个样本上的误差: 0.091985931\n",
      "Epoch:  272 每个样本上的误差: 0.104245152\n",
      "Epoch:  273 每个样本上的误差: 0.131174689\n",
      "Epoch:  274 每个样本上的误差: 0.099704629\n",
      "Epoch:  275 每个样本上的误差: 0.109958776\n",
      "Epoch:  276 每个样本上的误差: 0.092135887\n",
      "Epoch:  277 每个样本上的误差: 0.123722194\n",
      "Epoch:  278 每个样本上的误差: 0.122010262\n",
      "Epoch:  279 每个样本上的误差: 0.122722761\n",
      "Epoch:  280 每个样本上的误差: 0.105459063\n",
      "Epoch:  281 每个样本上的误差: 0.121187682\n",
      "Epoch:  282 每个样本上的误差: 0.102059718\n",
      "Epoch:  283 每个样本上的误差: 0.112332725\n",
      "Epoch:  284 每个样本上的误差: 0.135533310\n",
      "Epoch:  285 每个样本上的误差: 0.108724824\n",
      "Epoch:  286 每个样本上的误差: 0.103434702\n",
      "Epoch:  287 每个样本上的误差: 0.104191794\n",
      "Epoch:  288 每个样本上的误差: 0.085110408\n",
      "Epoch:  289 每个样本上的误差: 0.102356819\n",
      "Epoch:  290 每个样本上的误差: 0.114372822\n",
      "Epoch:  291 每个样本上的误差: 0.095517428\n",
      "Epoch:  292 每个样本上的误差: 0.094039439\n",
      "Epoch:  293 每个样本上的误差: 0.107471468\n",
      "Epoch:  294 每个样本上的误差: 0.114971155\n",
      "Epoch:  295 每个样本上的误差: 0.091550030\n",
      "Epoch:  296 每个样本上的误差: 0.119572092\n",
      "Epoch:  297 每个样本上的误差: 0.124505341\n",
      "Epoch:  298 每个样本上的误差: 0.106326367\n",
      "Epoch:  299 每个样本上的误差: 0.108360353\n",
      "Epoch:  300 每个样本上的误差: 0.118892240\n",
      "14422\n"
     ]
    }
   ],
   "source": [
    "W = []\n",
    "b = []\n",
    "Hidden_feature = []\n",
    "\n",
    "for j in range(1):\n",
    "    if j == 0:\n",
    "        X_train = standard_scale(data)\n",
    "    else:\n",
    "        X_train_pre = X_train\n",
    "        X_train = sdne[j-1].transform(X_train_pre)\n",
    "        Hidden_feature.append(X_train)\n",
    "    epoch=0\n",
    "    for epoch in range(300):\n",
    "        total_cost = 0.\n",
    "        total_batch = int(X_train.shape[0] / batch_size)\n",
    "\n",
    "        for k in range(total_batch):\n",
    "\n",
    "            batch_xs = get_random_block_from_data(X_train, batch_size)\n",
    "\n",
    "            cost = sdne[j].partial_fit(batch_xs)\n",
    "            total_cost=total_cost+cost\n",
    "        loss=total_cost/13460\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", \"%4d\" % (epoch + 1), \"每个样本上的误差:\", \"{:.9f}\".format(loss))\n",
    "            \n",
    "    if j == 0:\n",
    "        feat0 = sdne[0].transform(standard_scale(data))\n",
    "        print (len(feat0))\n",
    "        for feat in feat0:\n",
    "            for f in feat:\n",
    "                file1.write(str(f))\n",
    "                file1.write(\"\\t\")\n",
    "            file1.write(\"\\n\")\n",
    "file1.close()\n",
    "\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
