{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioritization comparison & classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import pandas as pd\n",
    "import json\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import sklearn.metrics\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "refset = \"farashi p-value cutoff\" # [\"farashi\", \"farashi p-value cutoff\", \"DeRycke\", \"Teslovich\"]\n",
    "classifier = \"LR\" # [\"LR\", \"RF\", \"SVM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/vlietstraw/git/Post-GWAS/ENSEMBL_mappings.json\", \"r\") as fp:\n",
    "    ensembl_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if refset == \"farashi\":\n",
    "    # Load the reference set\n",
    "    ref = pd.read_csv(\"~/git/Post-GWAS/Input sets/Farashi/Farashi full 2000000 bp distance no pvalue filtering.csv\")\n",
    "    ref[\"nodeID\"] = [ensembl_dict[x] if x in ensembl_dict.keys() else None for x in ref[\"gene_ids\"]]\n",
    "    \n",
    "    # Load the DIAMOnD results\n",
    "    diamond = pd.read_csv(\"~/git/Post-GWAS/DIAMOND/farashi diamond predictions with bp distance depict.csv\", delimiter = \";\", decimal = \",\")\n",
    "    diamond.columns = [\"nodeID\", \"unknown1\", \"unknown2\", \"DIAMOND predicted\", \"chromosome\", \"Class\", \"DIAMOND For-SNP rank\"]\n",
    "    diamond = diamond[[\"nodeID\", \"DIAMOND predicted\", \"chromosome\", \"DIAMOND For-SNP rank\"]]\n",
    "    diamond[\"chromosome\"] = diamond[\"chromosome\"].astype(str)\n",
    "    ref[\"chromosome\"] = ref[\"chromosome\"].astype(str)\n",
    "    diamond.drop(columns = [\"DIAMOND For-SNP rank\"], inplace = True)\n",
    "    diamond_temp = ref[[\"nodeID\", \"chromosome\", \"SNP ID\"]].merge(diamond, on = [\"nodeID\", \"chromosome\"])\n",
    "    diamond_temp = diamond_temp.sort_values([\"SNP ID\", \"DIAMOND predicted\"], ascending = True)\n",
    "    diamond_temp[\"DIAMOND For SNP rank\"] = diamond_temp.groupby(\"SNP ID\").cumcount() + 1\n",
    "    \n",
    "    # Merge with DIAMOND\n",
    "    ref = ref.merge(diamond_temp, how = \"left\", on = [\"nodeID\", \"SNP ID\", \"chromosome\"])\n",
    "    \n",
    "    # Load the DEPICT results\n",
    "    depict = pd.read_csv(\"~/git/DEPICT/outcomes/Farashi complete 2nd round/farashi_no_pvalue_filtering_geneprioritization.txt\", sep = \"\\t\")\n",
    "    depict[\"Locus\"] = depict[\"Locus\"].astype(str).apply(lambda x: x.split(\";\"))\n",
    "    depict = depict.explode(\"Locus\")\n",
    "\n",
    "    snp_replacement_dict = {\"rs113645266\" : \"rs6557271\",\n",
    "                    \"rs150282463\" : \"rs13137700\",\n",
    "                    \"rs67276543\" : \"rs34884832\"}\n",
    "    depict[\"Locus\"] = depict[\"Locus\"].replace(snp_replacement_dict)\n",
    "\n",
    "    depict = depict[[\"Locus\", \"Ensembl gene ID\", \"Nominal P value\"]]\n",
    "    depict.columns = [\"SNP ID\", \"gene_ids\", \"DEPICT p-value\"]\n",
    "    depict = depict.sort_values([\"SNP ID\", \"DEPICT p-value\"], ascending = True)\n",
    "    depict[\"DEPICT For SNP rank\"] = depict.groupby(\"SNP ID\").cumcount() + 1\n",
    "\n",
    "    ref = ref.merge(depict, on = [\"SNP ID\", \"gene_ids\"], how = \"inner\")\n",
    "    \n",
    "    # Load the EVOKE results\n",
    "    \n",
    "    EVOKE = pd.read_csv(\"~/git/Post-GWAS/EVOKE/farashi normal RF depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    EVOKE.columns = [\"SNP ID\", \"nodeID\", \"EVOKE_score\", \"Class\", \"EVOKE For SNP rank\"]\n",
    "    ref = ref.merge(EVOKE, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the network distance results\n",
    "    \n",
    "    distance = pd.read_csv(\"~/git/Post-GWAS/Network statistics/farashi RF depict 20-09-2021.csv\", delimiter = \";\")\n",
    "    distance.columns = [\"SNP ID\", \"nodeID\", \"distance_score\", \"Class\", \"network distance For SNP rank\"]\n",
    "    ref = ref.merge(distance, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the node2vec results\n",
    "    \n",
    "    node2vec_normal = pd.read_csv(\"~/git/Post-GWAS/Node2vec/farashi normal SVM depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_normal.columns = [\"SNP ID\", \"nodeID\", \"node2vec_normal_score\", \"Class\", \"node2vec normal For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_normal, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_graphlet = pd.read_csv(\"~/git/Post-GWAS/Node2vec/farashi graphlet LR depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_graphlet.columns = [\"SNP ID\", \"nodeID\", \"node2vec_graphlet_score\", \"Class\", \"node2vec graphlet For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_graphlet, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_autoencode = pd.read_csv(\"~/git/Post-GWAS/Node2vec/farashi autoencode LR depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_autoencode.columns = [\"SNP ID\", \"nodeID\", \"node2vec_autoencode_score\", \"Class\", \"node2vec autoencode For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_autoencode, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_combi = pd.read_csv(\"~/git/Post-GWAS/Node2vec/farashi combi SVM depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_combi.columns = [\"SNP ID\", \"nodeID\", \"node2vec_combi_score\", \"Class\", \"node2vec combi For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_combi, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the predicates results\n",
    "    \n",
    "    predicates = pd.read_csv(\"~/git/Post-GWAS/Predicates/farashi incoming LR depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    predicates.columns = [\"SNP ID\", \"gene_ids\", \"predicates_score\", \"Class\", \"predicates For SNP rank\"]\n",
    "    ref = ref.merge(predicates, how = \"left\", on = [\"SNP ID\", \"gene_ids\", \"Class\"])\n",
    "    \n",
    "    # Load the RDF2vec results\n",
    "    \n",
    "    rdf2vec = pd.read_csv(\"~/git/Post-GWAS/RDF2vec/farashi normal SVM depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    rdf2vec.columns = [\"SNP ID\", \"gene_ids\", \"rdf2vec_score\", \"Class\", \"rdf2vec For SNP rank\"]\n",
    "    ref = ref.merge(rdf2vec, how = \"left\", on = [\"SNP ID\", \"gene_ids\", \"Class\"])\n",
    "    \n",
    "    # Load the Struc2vec results\n",
    "    \n",
    "    struc2vec = pd.read_csv(\"~/git/Post-GWAS/Struc2vec/farashi normal KNN9 depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    struc2vec.columns = [\"SNP ID\", \"nodeID\", \"struc2vec_score\", \"Class\", \"struc2vec For SNP rank\"]\n",
    "    ref = ref.merge(struc2vec, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if refset == \"farashi p-value cutoff\":\n",
    "    # Load the reference set\n",
    "    ref = pd.read_csv(\"~/git/Post-GWAS/Input sets/Farashi/Farashi full 2000000 bp distance no pvalue filtering.csv\")\n",
    "    ref[\"nodeID\"] = [ensembl_dict[x] if x in ensembl_dict.keys() else None for x in ref[\"gene_ids\"]]\n",
    "    \n",
    "    # Load the DIAMOnD results\n",
    "    diamond = pd.read_csv(\"~/git/Post-GWAS/DIAMOND/farashi p-value cutoff diamond predictions with bp distance depict.csv\", delimiter = \";\", decimal = \",\")\n",
    "    diamond.columns = [\"nodeID\", \"unknown1\", \"unknown2\", \"DIAMOND predicted\", \"chromosome\", \"Class\", \"DIAMOND For-SNP rank\"]\n",
    "    diamond = diamond[[\"nodeID\", \"DIAMOND predicted\", \"chromosome\", \"DIAMOND For-SNP rank\"]]\n",
    "    diamond[\"chromosome\"] = diamond[\"chromosome\"].astype(str)\n",
    "    ref[\"chromosome\"] = ref[\"chromosome\"].astype(str)\n",
    "    diamond.drop(columns = [\"DIAMOND For-SNP rank\"], inplace = True)\n",
    "    diamond_temp = ref[[\"nodeID\", \"chromosome\", \"SNP ID\"]].merge(diamond, on = [\"nodeID\", \"chromosome\"])\n",
    "    diamond_temp = diamond_temp.sort_values([\"SNP ID\", \"DIAMOND predicted\"], ascending = True)\n",
    "    diamond_temp[\"DIAMOND For SNP rank\"] = diamond_temp.groupby(\"SNP ID\").cumcount() + 1\n",
    "    \n",
    "    # Merge with DIAMOND\n",
    "    ref = ref.merge(diamond_temp, how = \"left\", on = [\"nodeID\", \"SNP ID\", \"chromosome\"])\n",
    "    \n",
    "    # Load the DEPICT results\n",
    "    depict = pd.read_csv(\"~/git/DEPICT/outcomes/Farashi complete 2nd round/farashi_default_pvalue_filtering_geneprioritization.txt\", sep = \"\\t\")\n",
    "    depict[\"Locus\"] = depict[\"Locus\"].astype(str).apply(lambda x: x.split(\";\"))\n",
    "    depict = depict.explode(\"Locus\")\n",
    "\n",
    "    snp_replacement_dict = {\"rs113645266\" : \"rs6557271\",\n",
    "                    \"rs150282463\" : \"rs13137700\",\n",
    "                    \"rs67276543\" : \"rs34884832\"}\n",
    "    depict[\"Locus\"] = depict[\"Locus\"].replace(snp_replacement_dict)\n",
    "\n",
    "    depict = depict[[\"Locus\", \"Ensembl gene ID\", \"Nominal P value\"]]\n",
    "    depict.columns = [\"SNP ID\", \"gene_ids\", \"DEPICT p-value\"]\n",
    "    depict = depict.sort_values([\"SNP ID\", \"DEPICT p-value\"], ascending = True)\n",
    "    depict[\"DEPICT For SNP rank\"] = depict.groupby(\"SNP ID\").cumcount() + 1\n",
    "\n",
    "    ref = ref.merge(depict, on = [\"SNP ID\", \"gene_ids\"], how = \"inner\")\n",
    "    \n",
    "    # Load the EVOKE results\n",
    "    \n",
    "    EVOKE = pd.read_csv(\"~/git/Post-GWAS/EVOKE/farashi p-value cutoff log KNN7 depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    EVOKE.columns = [\"SNP ID\", \"nodeID\", \"EVOKE_score\", \"Class\", \"EVOKE For SNP rank\"]\n",
    "    ref = ref.merge(EVOKE, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the network distance results\n",
    "    \n",
    "    distance = pd.read_csv(\"~/git/Post-GWAS/Network statistics/farashi p-value cutoff LR depict 20-09-2021.csv\", delimiter = \";\")\n",
    "    distance.columns = [\"SNP ID\", \"nodeID\", \"distance_score\", \"Class\", \"network distance For SNP rank\"]\n",
    "    ref = ref.merge(distance, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the node2vec results\n",
    "    \n",
    "    node2vec_normal = pd.read_csv(\"~/git/Post-GWAS/Node2vec/farashi p-value cutoff normal KNN7 depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_normal.columns = [\"SNP ID\", \"nodeID\", \"node2vec_normal_score\", \"Class\", \"node2vec normal For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_normal, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_graphlet = pd.read_csv(\"~/git/Post-GWAS/Node2vec/farashi p-value cutoff graphlet KNN3 depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_graphlet.columns = [\"SNP ID\", \"nodeID\", \"node2vec_graphlet_score\", \"Class\", \"node2vec graphlet For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_graphlet, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_autoencode = pd.read_csv(\"~/git/Post-GWAS/Node2vec/farashi p-value cutoff autoencode LR depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_autoencode.columns = [\"SNP ID\", \"nodeID\", \"node2vec_autoencode_score\", \"Class\", \"node2vec autoencode For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_autoencode, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_combi = pd.read_csv(\"~/git/Post-GWAS/Node2vec/farashi p-value cutoff combi SVM depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_combi.columns = [\"SNP ID\", \"nodeID\", \"node2vec_combi_score\", \"Class\", \"node2vec combi For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_combi, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the predicates results\n",
    "    \n",
    "    predicates = pd.read_csv(\"~/git/Post-GWAS/Predicates/farashi p-value cutoff incoming KNN9 depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    predicates.columns = [\"SNP ID\", \"gene_ids\", \"predicates_score\", \"Class\", \"predicates For SNP rank\"]\n",
    "    ref = ref.merge(predicates, how = \"left\", on = [\"SNP ID\", \"gene_ids\", \"Class\"])\n",
    "    \n",
    "    # Load the RDF2vec results\n",
    "    \n",
    "    rdf2vec = pd.read_csv(\"~/git/Post-GWAS/RDF2vec/farashi p-value cutoff normal RF depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    rdf2vec.columns = [\"SNP ID\", \"gene_ids\", \"rdf2vec_score\", \"Class\", \"rdf2vec For SNP rank\"]\n",
    "    ref = ref.merge(rdf2vec, how = \"left\", on = [\"SNP ID\", \"gene_ids\", \"Class\"])\n",
    "    \n",
    "    # Load the Struc2vec results\n",
    "    \n",
    "    struc2vec = pd.read_csv(\"~/git/Post-GWAS/Struc2vec/farashi p-value cutoff graphlet KNN7 depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    struc2vec.columns = [\"SNP ID\", \"nodeID\", \"struc2vec_score\", \"Class\", \"struc2vec For SNP rank\"]\n",
    "    ref = ref.merge(struc2vec, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if refset == \"DeRycke\":\n",
    "    # Load the reference set\n",
    "    ref = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Input sets/DeRycke/DeRycke reference set.csv\", delimiter = \";\")\n",
    "    ref.columns = [\"SNP ID\", \"chromosome\", \"location\", \"gene_ids\", \"gene name\", \"gene start\", \"gene stop\", \"Diff expression\", \"Class\", \"bp distance absolute\", \"bp distance\", \"Gene rank\"]\n",
    "    ref[\"nodeID\"] = [ensembl_dict[x] if x in ensembl_dict.keys() else None for x in ref[\"gene_ids\"]]\n",
    "    \n",
    "    # Load the DIAMOnD results\n",
    "    diamond = pd.read_csv(\"~/git/Post-GWAS/DIAMOND/DeRycke diamond predictions with bp distance depict.csv\", delimiter = \";\", decimal = \",\")\n",
    "    diamond.columns = [\"nodeID\", \"unknown1\", \"unknown2\", \"DIAMOND predicted\", \"chromosome\", \"Class\", \"DIAMOND For-SNP rank\"]\n",
    "    diamond = diamond[[\"nodeID\", \"DIAMOND predicted\", \"chromosome\", \"DIAMOND For-SNP rank\"]]\n",
    "    diamond[\"chromosome\"] = diamond[\"chromosome\"].astype(str)\n",
    "    ref[\"chromosome\"] = ref[\"chromosome\"].astype(str)\n",
    "    diamond.drop(columns = [\"DIAMOND For-SNP rank\"], inplace = True)\n",
    "    diamond_temp = ref[[\"nodeID\", \"chromosome\", \"SNP ID\"]].merge(diamond, on = [\"nodeID\", \"chromosome\"])\n",
    "    diamond_temp = diamond_temp.sort_values([\"SNP ID\", \"DIAMOND predicted\"], ascending = True)\n",
    "    diamond_temp[\"DIAMOND For SNP rank\"] = diamond_temp.groupby(\"SNP ID\").cumcount() + 1\n",
    "    \n",
    "    # Merge with DIAMOND\n",
    "    ref = ref.merge(diamond_temp, how = \"left\", on = [\"nodeID\", \"SNP ID\", \"chromosome\"])\n",
    "    \n",
    "    # Load the DEPICT results\n",
    "    depict = pd.read_csv(\"~/git/DEPICT/outcomes/DeRycke/DeRycke_output_geneprioritization.txt\", sep = \"\\t\")\n",
    "    depict[\"Locus\"] = depict[\"Locus\"].astype(str).apply(lambda x: x.split(\";\"))\n",
    "    depict = depict.explode(\"Locus\")\n",
    "\n",
    "    snp_replacement_dict = {\"rs113645266\" : \"rs6557271\",\n",
    "                    \"rs150282463\" : \"rs13137700\",\n",
    "                    \"rs67276543\" : \"rs34884832\"}\n",
    "    depict[\"Locus\"] = depict[\"Locus\"].replace(snp_replacement_dict)\n",
    "\n",
    "    depict = depict[[\"Locus\", \"Ensembl gene ID\", \"Nominal P value\"]]\n",
    "    depict.columns = [\"SNP ID\", \"gene_ids\", \"DEPICT p-value\"]\n",
    "    depict = depict.sort_values([\"SNP ID\", \"DEPICT p-value\"], ascending = True)\n",
    "    depict[\"DEPICT For SNP rank\"] = depict.groupby(\"SNP ID\").cumcount() + 1\n",
    "\n",
    "    ref = ref.merge(depict, on = [\"SNP ID\", \"gene_ids\"], how = \"inner\")\n",
    "    \n",
    "    # Load the EVOKE results\n",
    "    \n",
    "    EVOKE = pd.read_csv(\"~/git/Post-GWAS/EVOKE/DeRycke log DT depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    EVOKE.columns = [\"SNP ID\", \"nodeID\", \"EVOKE_score\", \"Class\", \"EVOKE For SNP rank\"]\n",
    "    ref = ref.merge(EVOKE, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the network distance results\n",
    "    \n",
    "    distance = pd.read_csv(\"~/git/Post-GWAS/Network statistics/DeRycke RF depict 20-09-2021.csv\", delimiter = \";\")\n",
    "    distance.columns = [\"SNP ID\", \"nodeID\", \"distance_score\", \"Class\", \"network distance For SNP rank\"]\n",
    "    ref = ref.merge(distance, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the node2vec results\n",
    "    \n",
    "    node2vec_normal = pd.read_csv(\"~/git/Post-GWAS/Node2vec/DeRycke normal KNN9 depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_normal.columns = [\"SNP ID\", \"nodeID\", \"node2vec_normal_score\", \"Class\", \"node2vec normal For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_normal, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_graphlet = pd.read_csv(\"~/git/Post-GWAS/Node2vec/DeRycke graphlet LR depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_graphlet.columns = [\"SNP ID\", \"nodeID\", \"node2vec_graphlet_score\", \"Class\", \"node2vec graphlet For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_graphlet, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_autoencode = pd.read_csv(\"~/git/Post-GWAS/Node2vec/DeRycke autoencode KNN3 depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_autoencode.columns = [\"SNP ID\", \"nodeID\", \"node2vec_autoencode_score\", \"Class\", \"node2vec autoencode For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_autoencode, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_combi = pd.read_csv(\"~/git/Post-GWAS/Node2vec/DeRycke combi LR depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_combi.columns = [\"SNP ID\", \"nodeID\", \"node2vec_combi_score\", \"Class\", \"node2vec combi For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_combi, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the predicates results\n",
    "    \n",
    "    predicates = pd.read_csv(\"~/git/Post-GWAS/Predicates/DeRycke outgoing DT depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    predicates.columns = [\"SNP ID\", \"gene_ids\", \"predicates_score\", \"Class\", \"predicates For SNP rank\"]\n",
    "    ref = ref.merge(predicates, how = \"left\", on = [\"SNP ID\", \"gene_ids\", \"Class\"])\n",
    "    \n",
    "    # Load the RDF2vec results\n",
    "    \n",
    "    rdf2vec = pd.read_csv(\"~/git/Post-GWAS/RDF2vec/DeRycke autoencode SVM depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    rdf2vec.columns = [\"SNP ID\", \"gene_ids\", \"rdf2vec_score\", \"Class\", \"rdf2vec For SNP rank\"]\n",
    "    ref = ref.merge(rdf2vec, how = \"left\", on = [\"SNP ID\", \"gene_ids\", \"Class\"])\n",
    "    \n",
    "    # Load the Struc2vec results\n",
    "    \n",
    "    struc2vec = pd.read_csv(\"~/git/Post-GWAS/Struc2vec/DeRycke combi KNN3 depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    struc2vec.columns = [\"SNP ID\", \"nodeID\", \"struc2vec_score\", \"Class\", \"struc2vec For SNP rank\"]\n",
    "    ref = ref.merge(struc2vec, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if refset == \"Teslovich\":\n",
    "    # Load the reference set\n",
    "    ref = pd.read_csv(\"/Users/vlietstraw/git/Post-GWAS/Input sets/Teslovich/Teslovich reference set.csv\")\n",
    "    ref.columns = [\"SNP ID\", \"chromosome\", \"location\", \"P\", \"gene_ids\", \"gene name\", \"gene start\", \"gene stop\", \"Class\", \"bp distance absolute\", \"bp distance\", \"Gene rank\"]\n",
    "    ref[\"nodeID\"] = [ensembl_dict[x] if x in ensembl_dict.keys() else None for x in ref[\"gene_ids\"]]\n",
    "    \n",
    "    # Load the DIAMOnD results\n",
    "    diamond = pd.read_csv(\"~/git/Post-GWAS/DIAMOND/Teslovich diamond predictions with bp distance depict.csv\", delimiter = \";\", decimal = \",\")\n",
    "    diamond.columns = [\"nodeID\", \"unknown1\", \"unknown2\", \"DIAMOND predicted\", \"chromosome\", \"Class\", \"DIAMOND For-SNP rank\"]\n",
    "    diamond = diamond[[\"nodeID\", \"DIAMOND predicted\", \"chromosome\", \"DIAMOND For-SNP rank\"]]\n",
    "    diamond[\"chromosome\"] = diamond[\"chromosome\"].astype(str)\n",
    "    ref[\"chromosome\"] = ref[\"chromosome\"].astype(str)\n",
    "    diamond.drop(columns = [\"DIAMOND For-SNP rank\"], inplace = True)\n",
    "    diamond_temp = ref[[\"nodeID\", \"chromosome\", \"SNP ID\"]].merge(diamond, on = [\"nodeID\", \"chromosome\"])\n",
    "    diamond_temp = diamond_temp.sort_values([\"SNP ID\", \"DIAMOND predicted\"], ascending = True)\n",
    "    diamond_temp[\"DIAMOND For SNP rank\"] = diamond_temp.groupby(\"SNP ID\").cumcount() + 1\n",
    "    \n",
    "    # Merge with DIAMOND\n",
    "    ref = ref.merge(diamond_temp, how = \"left\", on = [\"nodeID\", \"SNP ID\", \"chromosome\"])\n",
    "    \n",
    "    # Load the DEPICT results\n",
    "    depict = pd.read_csv(\"~/git/DEPICT/outcomes/Teslovich for paper Wytze/Teslovich_output_geneprioritization.txt\", sep = \"\\t\")\n",
    "    depict[\"Locus\"] = depict[\"Locus\"].astype(str).apply(lambda x: x.split(\";\"))\n",
    "    depict = depict.explode(\"Locus\")\n",
    "\n",
    "    snp_replacement_dict = {\"rs113645266\" : \"rs6557271\",\n",
    "                    \"rs150282463\" : \"rs13137700\",\n",
    "                    \"rs67276543\" : \"rs34884832\"}\n",
    "    depict[\"Locus\"] = depict[\"Locus\"].replace(snp_replacement_dict)\n",
    "\n",
    "    depict = depict[[\"Locus\", \"Ensembl gene ID\", \"Nominal P value\"]]\n",
    "    depict.columns = [\"SNP ID\", \"gene_ids\", \"DEPICT p-value\"]\n",
    "    depict = depict.sort_values([\"SNP ID\", \"DEPICT p-value\"], ascending = True)\n",
    "    depict[\"DEPICT For SNP rank\"] = depict.groupby(\"SNP ID\").cumcount() + 1\n",
    "\n",
    "    ref = ref.merge(depict, on = [\"SNP ID\", \"gene_ids\"], how = \"inner\")\n",
    "    \n",
    "    # Load the EVOKE results\n",
    "    \n",
    "    EVOKE = pd.read_csv(\"~/git/Post-GWAS/EVOKE/Teslovich log LR depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    EVOKE.columns = [\"SNP ID\", \"nodeID\", \"EVOKE_score\", \"Class\", \"EVOKE For SNP rank\"]\n",
    "    ref = ref.merge(EVOKE, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the network distance results\n",
    "    \n",
    "    distance = pd.read_csv(\"~/git/Post-GWAS/Network statistics/Teslovich LR depict 20-09-2021.csv\", delimiter = \";\")\n",
    "    distance.columns = [\"SNP ID\", \"nodeID\", \"distance_score\", \"Class\", \"network distance For SNP rank\"]\n",
    "    ref = ref.merge(distance, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the node2vec results\n",
    "    \n",
    "    node2vec_normal = pd.read_csv(\"~/git/Post-GWAS/Node2vec/Teslovich normal KNN1 depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_normal.columns = [\"SNP ID\", \"nodeID\", \"node2vec_normal_score\", \"Class\", \"node2vec normal For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_normal, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_graphlet = pd.read_csv(\"~/git/Post-GWAS/Node2vec/Teslovich graphlet KNN1 depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_graphlet.columns = [\"SNP ID\", \"nodeID\", \"node2vec_graphlet_score\", \"Class\", \"node2vec graphlet For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_graphlet, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_autoencode = pd.read_csv(\"~/git/Post-GWAS/Node2vec/Teslovich autoencode SVM depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_autoencode.columns = [\"SNP ID\", \"nodeID\", \"node2vec_autoencode_score\", \"Class\", \"node2vec autoencode For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_autoencode, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    node2vec_combi = pd.read_csv(\"~/git/Post-GWAS/Node2vec/Teslovich combi SVM depict 18-09-2021.csv\", delimiter = \";\")\n",
    "    node2vec_combi.columns = [\"SNP ID\", \"nodeID\", \"node2vec_combi_score\", \"Class\", \"node2vec combi For SNP rank\"]\n",
    "    ref = ref.merge(node2vec_combi, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])\n",
    "    \n",
    "    # Load the predicates results\n",
    "    \n",
    "    predicates = pd.read_csv(\"~/git/Post-GWAS/Predicates/Teslovich outgoing SVM depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    predicates.columns = [\"SNP ID\", \"gene_ids\", \"predicates_score\", \"Class\", \"predicates For SNP rank\"]\n",
    "    ref = ref.merge(predicates, how = \"left\", on = [\"SNP ID\", \"gene_ids\", \"Class\"])\n",
    "    \n",
    "    # Load the RDF2vec results\n",
    "    \n",
    "    rdf2vec = pd.read_csv(\"~/git/Post-GWAS/RDF2vec/Teslovich autoencode RF depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    rdf2vec.columns = [\"SNP ID\", \"gene_ids\", \"rdf2vec_score\", \"Class\", \"rdf2vec For SNP rank\"]\n",
    "    ref = ref.merge(rdf2vec, how = \"left\", on = [\"SNP ID\", \"gene_ids\", \"Class\"])\n",
    "    \n",
    "    # Load the Struc2vec results\n",
    "    \n",
    "    struc2vec = pd.read_csv(\"~/git/Post-GWAS/Struc2vec/Teslovich normal KNN5 depict 17-09-2021.csv\", delimiter = \";\")\n",
    "    struc2vec.columns = [\"SNP ID\", \"nodeID\", \"struc2vec_score\", \"Class\", \"struc2vec For SNP rank\"]\n",
    "    ref = ref.merge(struc2vec, how = \"left\", on = [\"SNP ID\", \"nodeID\", \"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier based on rankings (with different combinations)\n",
    "scores = [\"bp distance absolute\", \"DEPICT p-value\", \"predicates_score\", \"node2vec_normal_score\", \"node2vec_graphlet_score\",\n",
    "          \"node2vec_autoencode_score\", \"node2vec_combi_score\", \"distance_score\", \"EVOKE_score\", \"rdf2vec_score\", \"struc2vec_score\"] # \"DIAMOND predicted\",\n",
    "ranks = [\"Gene rank\", \"DEPICT For SNP rank\", \"predicates For SNP rank\", \"node2vec normal For SNP rank\", \"node2vec graphlet For SNP rank\", \"node2vec autoencode For SNP rank\" , \"node2vec combi For SNP rank\" ,\n",
    "         \"network distance For SNP rank\", \"EVOKE For SNP rank\", \"rdf2vec For SNP rank\", \"struc2vec For SNP rank\"] # \"DIAMOND For SNP rank\",\n",
    "\n",
    "scores_combos = list(combinations(scores, 2)) + list(combinations(scores, 3)) + list(combinations(scores, 4)) + list(combinations(scores, 5)) + list(combinations(scores, 6)) + \\\n",
    "                list(combinations(scores, 7)) + list(combinations(scores, 8)) + list(combinations(scores, 9)) + list(combinations(scores, 10)) + [scores]\n",
    "ranks_combos = list(combinations(ranks, 2)) + list(combinations(ranks, 3)) + list(combinations(ranks, 4)) + list(combinations(ranks, 5)) + list(combinations(ranks, 6)) + \\\n",
    "                list(combinations(ranks, 7)) + list(combinations(ranks, 8)) + list(combinations(ranks, 9)) + list(combinations(ranks, 10)) + [ranks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare rankings\n",
    "ref[\"lowest rank\"] = ref[ranks].min(axis = 0)\n",
    "ref[(ref[\"lowest rank\"] == 1) & (ref[\"Class\"] == 1)]\n",
    "ref[(ref[\"lowest rank\"] <= 3) & (ref[\"Class\"] == 1)]\n",
    "ref[\"lowest rank\"][ref[\"Class\"] == 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(index = range(1, len(scores_combos) + 1), columns = scores)\n",
    "scores_df = scores_df.fillna(False)\n",
    "indx = 1\n",
    "for s in scores_combos:\n",
    "    #print(\"Analyzing \" + str(indx) + \" out of \" + str(len(scores_df)))\n",
    "    scores_df.at[indx, list(s)] = True\n",
    "    \n",
    "    f = ref.copy()\n",
    "    f = f[[\"chromosome\", \"Class\", \"SNP ID\", \"gene_ids\"] + list(s)]\n",
    "    f.dropna(subset = list(s), inplace = True)\n",
    "    \n",
    "    # Drop all SNPs which no longer have a positive case\n",
    "    pos_counts = f.groupby(\"SNP ID\")[\"Class\"].sum()\n",
    "    f = f[~f[\"SNP ID\"].isin(pos_counts[pos_counts == 0].index)]\n",
    "    \n",
    "    outcomes = pd.DataFrame()\n",
    "\n",
    "    chromosomes = list(set(f[\"chromosome\"]))\n",
    "\n",
    "    for chrom in chromosomes:\n",
    "        #print(\"Predicting candidates for chromosome \" + str(chrom))\n",
    "\n",
    "        f_test = f[f[\"chromosome\"] == chrom].copy()\n",
    "        f_train = f[f[\"chromosome\"] != chrom].copy()\n",
    "\n",
    "        train_class = f_train[\"Class\"]\n",
    "        test_class = f_test[\"Class\"]\n",
    "        \n",
    "        test_snps = f_test[\"SNP ID\"]\n",
    "        test_genes = f_test[\"gene_ids\"]\n",
    "\n",
    "        f_test.drop(columns = [\"Class\", \"chromosome\", \"SNP ID\", \"gene_ids\"], inplace = True)\n",
    "        f_train.drop(columns = [\"Class\", \"chromosome\", \"SNP ID\", \"gene_ids\"], inplace = True)\n",
    "        \n",
    "        if classifier == \"SVM\":\n",
    "            clf = SVR(gamma=\"auto\")\n",
    "        if classifier == \"LR\":\n",
    "            from warnings import filterwarnings\n",
    "            filterwarnings('ignore')\n",
    "            clf = LogisticRegression(max_iter = 10000)\n",
    "        if classifier == \"RF\":\n",
    "            clf = RandomForestRegressor(n_estimators = 1000, n_jobs = -1, max_features = \"sqrt\", max_depth = 5)\n",
    "        clf.fit(f_train, train_class)\n",
    "        \n",
    "        if classifier == \"LR\":\n",
    "            outcomes = pd.concat([outcomes, pd.DataFrame({\"predicted\" : clf.predict_proba(f_test)[:,1],\n",
    "                                                           \"chromsome\" : chrom,\n",
    "                                                           \"Class\" : test_class,\n",
    "                                                           \"SNP ID\" : test_snps,\n",
    "                                                           \"ENSEMBL\" : test_genes})])\n",
    "        else:\n",
    "            outcomes = pd.concat([outcomes, pd.DataFrame({\"predicted\" : clf.predict(f_test),\n",
    "                                               \"chromsome\" : chrom,\n",
    "                                               \"Class\" : test_class,\n",
    "                                               \"SNP ID\" : test_snps,\n",
    "                                               \"ENSEMBL\" : test_genes})])\n",
    "            \n",
    "    if len(outcomes) > 0:\n",
    "        outcomes = outcomes.sort_values([\"SNP ID\", \"predicted\"], ascending = False)\n",
    "        outcomes[\"For-SNP rank\"] = outcomes.groupby(\"SNP ID\").cumcount() + 1\n",
    "\n",
    "        scores_df.at[indx, \"Recall snps\"] = len(set(outcomes[\"SNP ID\"]))\n",
    "        scores_df.at[indx, \"Recall genes\"] = len(set(outcomes[\"ENSEMBL\"]))\n",
    "        scores_df.at[indx, \"Recall entries\"] = sum(outcomes[\"Class\"])\n",
    "\n",
    "        fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcomes[\"Class\"], -outcomes[\"For-SNP rank\"], pos_label = 1)\n",
    "        scores_df.at[indx, \"ROC-AUC overall (lso)\"] = sklearn.metrics.auc(fpr, tpr) * 100\n",
    "\n",
    "        # Calculate the ROC-AUC for every SNP and average the result\n",
    "        SNPS2 = list(set(outcomes[\"SNP ID\"]))\n",
    "        aucs = []\n",
    "        for snp in SNPS2:\n",
    "          if len(set(outcomes[\"Class\"][outcomes[\"SNP ID\"] == snp])) == 1:\n",
    "              aucs.append(list(set(outcomes[\"Class\"][outcomes[\"SNP ID\"] == snp]))[0])\n",
    "          else:\n",
    "              fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcomes[\"Class\"][outcomes[\"SNP ID\"] == snp], outcomes[\"predicted\"][outcomes[\"SNP ID\"] == snp], pos_label = 1)\n",
    "              aucs.append(sklearn.metrics.auc(fpr, tpr))\n",
    "        scores_df.at[indx, \"ROC-AUC - mean per snpl (lso)\"] = sum(aucs)/len(aucs)\n",
    "\n",
    "\n",
    "        outcomes = outcomes.sort_values([\"SNP ID\", \"predicted\"], ascending = False)\n",
    "        SNP_temp = 0\n",
    "        counter = 0\n",
    "        prediction_temp = 9999\n",
    "        for indx2, row in outcomes.iterrows():\n",
    "            if SNP_temp != row[\"SNP ID\"]:\n",
    "                SNP_temp = row[\"SNP ID\"]\n",
    "                counter = 1\n",
    "                prediction_temp = row[\"predicted\"]\n",
    "            elif SNP_temp == row[\"SNP ID\"] and prediction_temp != row[\"predicted\"]:\n",
    "                counter += 1\n",
    "                prediction_temp = row[\"predicted\"]\n",
    "            ref.at[indx2, \"For-SNP rank\"] = counter\n",
    "\n",
    "        # In[22]:\n",
    "\n",
    "        # Calculate hits @1\n",
    "        scores_df.at[indx, \"Hits@1(lso)\"] = sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] == 1)])\n",
    "\n",
    "        # In[23]:\n",
    "\n",
    "        # Calculate hits @3\n",
    "        scores_df.at[indx, \"Hits@3(lso)\"] = sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] <= 3)])\n",
    "\n",
    "        # In[24]:\n",
    "\n",
    "        # Calculate hits @5\n",
    "        scores_df.at[indx, \"Hits@5(lso)\"] = sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] <= 5)])\n",
    "\n",
    "        # In[25]:\n",
    "\n",
    "        # Calculate hits @10\n",
    "        scores_df.at[indx, \"Hits@10(lso)\"] = sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] <= 10)])\n",
    "\n",
    "        # In[26]:\n",
    "\n",
    "        scores_df.at[indx, \"Mean rank (lso)\"] = outcomes[\"For-SNP rank\"][(outcomes[\"Class\"] == 1)].mean()\n",
    "\n",
    "        # In[27]:\n",
    "\n",
    "        scores_df.at[indx, \"Median rank (lso)\"] = outcomes[\"For-SNP rank\"][outcomes[\"Class\"] == 1].quantile(q = [0,0.25,0.5,0.75,1])[0.50]\n",
    "\n",
    "    indx += 1\n",
    "scores_df.to_csv(\"~/git/Post-GWAS/Ensemble results scores \" + refset + \" with classifier \" + classifier + \" \" + datetime.today().strftime(\"%d-%m-%Y\") + \".csv\", index = False, sep = \";\", decimal = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_df = pd.DataFrame(index = range(1, len(ranks_combos) + 1), columns = ranks)\n",
    "ranks_df = ranks_df.fillna(False)\n",
    "indx = 1\n",
    "for s in ranks_combos:\n",
    "    #print(\"Analyzing \" + str(indx) + \" out of \" + str(len(ranks_combos)))\n",
    "    ranks_df.at[indx, list(s)] = True\n",
    "    \n",
    "    f = ref.copy()\n",
    "    f = f[[\"chromosome\", \"Class\", \"SNP ID\", \"gene_ids\"] + list(s)]\n",
    "    f.dropna(subset = list(s), inplace = True)\n",
    "    \n",
    "    # Drop all SNPs which no longer have a positive case\n",
    "    pos_counts = f.groupby(\"SNP ID\")[\"Class\"].sum()\n",
    "    f = f[~f[\"SNP ID\"].isin(pos_counts[pos_counts == 0].index)]\n",
    "    \n",
    "    outcomes = pd.DataFrame()\n",
    "\n",
    "    chromosomes = list(set(f[\"chromosome\"]))\n",
    "\n",
    "    for chrom in chromosomes:\n",
    "        # print(\"Predicting candidates for chromosome \" + str(chrom))\n",
    "\n",
    "        f_test = f[f[\"chromosome\"] == chrom].copy()\n",
    "        f_train = f[f[\"chromosome\"] != chrom].copy()\n",
    "\n",
    "        train_class = f_train[\"Class\"]\n",
    "        test_class = f_test[\"Class\"]\n",
    "        \n",
    "        test_snps = f_test[\"SNP ID\"]\n",
    "        test_genes = f_test[\"gene_ids\"]\n",
    "\n",
    "        f_test.drop(columns = [\"Class\", \"chromosome\", \"SNP ID\", \"gene_ids\"], inplace = True)\n",
    "        f_train.drop(columns = [\"Class\", \"chromosome\", \"SNP ID\", \"gene_ids\"], inplace = True)\n",
    "        \n",
    "        if classifier == \"SVM\":\n",
    "            clf = SVR(gamma=\"auto\")\n",
    "        if classifier == \"LR\":\n",
    "            from warnings import filterwarnings\n",
    "            filterwarnings('ignore')\n",
    "            clf = LogisticRegression(max_iter = 10000)\n",
    "        if classifier == \"RF\":\n",
    "            clf = RandomForestRegressor(n_estimators = 1000, n_jobs = -1, max_features = \"sqrt\", max_depth = 5)\n",
    "        clf.fit(f_train, train_class)\n",
    "\n",
    "        if classifier == \"LR\":\n",
    "            outcomes = pd.concat([outcomes, pd.DataFrame({\"predicted\" : clf.predict_proba(f_test)[:,1],\n",
    "                                                           \"chromsome\" : chrom,\n",
    "                                                           \"Class\" : test_class,\n",
    "                                                           \"SNP ID\" : test_snps,\n",
    "                                                           \"ENSEMBL\" : test_genes})])\n",
    "        else:\n",
    "            outcomes = pd.concat([outcomes, pd.DataFrame({\"predicted\" : clf.predict(f_test),\n",
    "                                               \"chromsome\" : chrom,\n",
    "                                               \"Class\" : test_class,\n",
    "                                               \"SNP ID\" : test_snps,\n",
    "                                               \"ENSEMBL\" : test_genes})])\n",
    "            \n",
    "    if len(outcomes) > 0:\n",
    "        outcomes = outcomes.sort_values([\"SNP ID\", \"predicted\"], ascending = False)\n",
    "        outcomes[\"For-SNP rank\"] = outcomes.groupby(\"SNP ID\").cumcount() + 1\n",
    "\n",
    "        ranks_df.at[indx, \"Recall snps\"] = len(set(outcomes[\"SNP ID\"]))\n",
    "        ranks_df.at[indx, \"Recall genes\"] = len(set(outcomes[\"ENSEMBL\"]))\n",
    "        ranks_df.at[indx, \"Recall entries\"] = sum(outcomes[\"Class\"])\n",
    "\n",
    "        fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcomes[\"Class\"], -outcomes[\"For-SNP rank\"], pos_label = 1)\n",
    "        ranks_df.at[indx, \"ROC-AUC overall (lso)\"] = sklearn.metrics.auc(fpr, tpr) * 100\n",
    "\n",
    "        # Calculate the ROC-AUC for every SNP and average the result\n",
    "        SNPS2 = list(set(outcomes[\"SNP ID\"]))\n",
    "        aucs = []\n",
    "        for snp in SNPS2:\n",
    "          if len(set(outcomes[\"Class\"][outcomes[\"SNP ID\"] == snp])) == 1:\n",
    "              aucs.append(list(set(outcomes[\"Class\"][outcomes[\"SNP ID\"] == snp]))[0])\n",
    "          else:\n",
    "              fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcomes[\"Class\"][outcomes[\"SNP ID\"] == snp], outcomes[\"predicted\"][outcomes[\"SNP ID\"] == snp], pos_label = 1)\n",
    "              aucs.append(sklearn.metrics.auc(fpr, tpr))\n",
    "        ranks_df.at[indx, \"ROC-AUC - mean per snpl (lso)\"] = sum(aucs)/len(aucs)\n",
    "\n",
    "\n",
    "        outcomes = outcomes.sort_values([\"SNP ID\", \"predicted\"], ascending = False)\n",
    "        SNP_temp = 0\n",
    "        counter = 0\n",
    "        prediction_temp = 9999\n",
    "        for indx2, row in outcomes.iterrows():\n",
    "            if SNP_temp != row[\"SNP ID\"]:\n",
    "                SNP_temp = row[\"SNP ID\"]\n",
    "                counter = 1\n",
    "                prediction_temp = row[\"predicted\"]\n",
    "            elif SNP_temp == row[\"SNP ID\"] and prediction_temp != row[\"predicted\"]:\n",
    "                counter += 1\n",
    "                prediction_temp = row[\"predicted\"]\n",
    "            ref.at[indx2, \"For-SNP rank\"] = counter\n",
    "\n",
    "        # In[22]:\n",
    "\n",
    "        # Calculate hits @1\n",
    "        ranks_df.at[indx, \"Hits@1(lso)\"] = sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] == 1)])\n",
    "\n",
    "        # In[23]:\n",
    "\n",
    "        # Calculate hits @3\n",
    "        ranks_df.at[indx, \"Hits@3(lso)\"] = sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] <= 3)])\n",
    "\n",
    "        # In[24]:\n",
    "\n",
    "        # Calculate hits @5\n",
    "        ranks_df.at[indx, \"Hits@5(lso)\"] = sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] <= 5)])\n",
    "\n",
    "        # In[25]:\n",
    "\n",
    "        # Calculate hits @10\n",
    "        ranks_df.at[indx, \"Hits@10(lso)\"] = sum(outcomes[\"Class\"][(outcomes[\"Class\"] == 1) & (outcomes[\"For-SNP rank\"] <= 10)])\n",
    "\n",
    "        # In[26]:\n",
    "\n",
    "        ranks_df.at[indx, \"Mean rank (lso)\"] = outcomes[\"For-SNP rank\"][(outcomes[\"Class\"] == 1)].mean()\n",
    "\n",
    "        # In[27]:\n",
    "\n",
    "        ranks_df.at[indx, \"Median rank (lso)\"] = outcomes[\"For-SNP rank\"][outcomes[\"Class\"] == 1].quantile(q = [0,0.25,0.5,0.75,1])[0.50]\n",
    "\n",
    "    indx += 1\n",
    "ranks_df.to_csv(\"~/git/Post-GWAS/Ensemble results ranks \" + refset + \" with classifier \" + classifier + \" \" + datetime.today().strftime(\"%d-%m-%Y\") + \".csv\", index = False, sep = \";\", decimal = \",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
